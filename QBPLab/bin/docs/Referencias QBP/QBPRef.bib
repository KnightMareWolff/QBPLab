@article{Sebastian2013,
abstract = {Abstract With the development of more and more sophisticated Music Information Retrieval approaches, aspects of adaptivity are becoming an increasingly important research topic. Even though, adaptive techniques have already found their way into Music Information ...},
annote = {Artigo Interessante fala sobre as oportunidades na cria{\c{c}}{\~{a}}o de metodos e algoritmos adaptaveis as necessidades das aplica{\c{c}}{\~{o}}es.
Cita apenas um pequeno trecho sobre similaridade porem {\'{e}} interessante para verificarmos o que j{\'{a}} existe neste sentido
Chaves: 
Music Similarity
State of The Art},
author = {{Sebastian Stober}, Andreas N{\"{u}}rnberger},
doi = {10.1007/s11042-012-1042-z},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sebastian Stober - 2013 - Adaptive music retrieval-a state of the art.pdf:pdf},
isbn = {4939167127},
issn = {13807501},
journal = {Multimedia Tools and Applications},
keywords = {Adaptive systems,Music information retrieval,Overview,Survey},
number = {3},
pages = {467--494},
title = {{Adaptive music retrieval-a state of the art}},
volume = {65},
year = {2013}
}
@article{Yu2013,
abstract = {With more and more multimedia content made available on the Internet, music information retrieval is becoming a critical but challenging research topic, especially for real-time online search of similar songs from websites. In this paper we study how to quickly and reliably retrieve relevant songs from a large-scale dataset of music audio tracks according to melody similarity. Our contributions are two-fold: (i) Compact and accurate representation of audio tracks by exploiting music semantics. Chord progressions are recognized from audio signals based on trained music rules, and the recognition accuracy is improved by multi-probing. A concise chord progression histogram (CPH) is computed from each audio track as a mid-level feature, which retains the discriminative capability in describing audio content. (ii) Efficient organization of audio tracks according to their CPHs by using only one locality sensitive hash table with a tree-structure. A set of dominant chord progressions of each song is used as the hash key. Average degradation of ranks is further defined to estimate the similarity of two songs in terms of their dominant chord progressions, and used to control the number of probing in the retrieval stage. Experimental results on a large dataset with 74,055 music audio tracks confirm the scalability of the proposed retrieval algorithm. Compared to state-of-the-art methods, our algorithm improves the accuracy of summarization and indexing, and makes a further step towards the optimal performance determined by an exhaustive sequence comparison. {\textcopyright} 1999-2013 IEEE.},
author = {Yu, Yi and Zimmermann, Roger and Wang, Ye and Oria, Vincent},
doi = {10.1109/TMM.2013.2269313},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2013 - Scalable content-based music retrieval using chord progression histogram and tree-structure LSH.pdf:pdf},
isbn = {1520-9210},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Audio computing,Chord progression histogram,Locality sensitive hashing,Music-IR,Tree-structure},
number = {8},
pages = {1969--1981},
title = {{Scalable content-based music retrieval using chord progression histogram and tree-structure LSH}},
volume = {15},
year = {2013}
}
@article{Duggan2011,
abstract = {This paper aims to describe the Tunepal project as an example of a music information retrieval (MIR) system that is having an impact on how musicians access, learn and play traditional Irish music around the world. This paper describes the functionality of the Tunepal system: consisting of the tune corpus, the web site tunepal.org and mobile apps supporting iOS and Android OS. Tunepal facilitates query-by-title and query-by-playing music (QBP) searches and allows a musician to retrieve and playback scores amongst other supported functions. Tunepal has been favorably received and musicians report that the system is being used in a variety of scenarios including archiving and the preparation of sleeve notes for commercial recordings. Tunepal has a growing user base in 25 countries. The comprehensive tune corpus (over 16,000 compositions), the query-by-playing technology and the fact that the mobile apps provide access to the corpus in situ in traditional music sessions and classes make this project uniquely useful.},
annote = {Artigo que descreve a hist{\'{o}}ria e funcionamento de um software de mercado baseado na nota{\c{c}}{\~{a}}o ABC , que possui busca de musicas com os snippets executados pelo musico de 20 segundos.
Este artigo {\'{e}} importante , pois foi o unico at{\'{e}} o momento queferindo-se como uma solu{\c{c}}{\~{a}}o Query-by-Playing, Porem tecnicamente n{\~{a}}o fala nada sobre o processo interno de busca.
Chaves: 
Music Similarity
QBP},
author = {Duggan, Bryan and O'Shea, Brendan},
doi = {10.1108/10650751111182597},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Duggan, O'Shea - 2011 - Tunepal searching a digital library of traditional music scores.pdf:pdf},
isbn = {1065075111},
issn = {1065-075X},
journal = {OCLC Systems {\&} Services: International digital library perspectives},
number = {4},
pages = {284--297},
title = {{Tunepal: searching a digital library of traditional music scores}},
url = {http://www.emeraldinsight.com/doi/10.1108/10650751111182597},
volume = {27},
year = {2011}
}
@article{Fujihara2010,
abstract = {This paper describes a method of modeling the characteristics of a singing voice from polyphonic musical audio signals including sounds of various musical instruments. Because singing voices play an important role in musical pieces with vocals, such representation is useful for music information retrieval systems. The main problem in modeling the characteristics of a singing voice is the negative influences caused by accompaniment sounds. To solve this problem, we developed two methods, {\textless}i{\textgreater}accompaniment sound reduction and reliable frame selection{\textless}/i{\textgreater} {\textless}b{\textgreater}.{\textless}/b{\textgreater} The former makes it possible to calculate feature vectors that represent a spectral envelope of a singing voice after reducing accompaniment sounds. It first extracts the harmonic components of the predominant melody from sound mixtures and then resynthesizes the melody by using a sinusoidal model driven by these components. The latter method then estimates the reliability of frame of the obtained melody (i.e., the influence of accompaniment sound) by using two Gaussian mixture models (GMMs) for vocal and nonvocal frames to select the reliable vocal portions of musical pieces. Finally, each song is represented by its GMM consisting of the reliable frames. This new representation of the singing voice is demonstrated to improve the performance of an automatic singer identification system and to achieve an MIR system based on vocal timbre similarity.},
annote = {Artigo muito interessante, utiliza dados simbolicos para machine learning e realiza o calculo de similaridade que n{\~{a}}o {\'{e}} comum nos outros artigos encontrados at{\'{e}} o momento.
O autor inclusive inclui questoes de pesquisa que me inspiraram na confec{\c{c}}{\~{a}}o das minhas proprias questoes de pesquisa para o Mestrado.
Chaves: 
Music Datasets
Music Similarity
Symetric Kullback-Leibler Divergence
Audio Processing},
author = {Fujihara, Hiromasa and Goto, Masataka and Kitahara, Tetsuro and Okuno, Hiroshi G.},
doi = {10.1109/TASL.2010.2041386},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fujihara et al. - 2010 - A modeling of singing voice robust to accompaniment sounds and its application to singer identification and voc.pdf:pdf},
isbn = {1520-9210},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Music information retrieval (MIR),Singer identification,Singing voice,Vocal,Vocal timbre similarity},
number = {3},
pages = {638--648},
title = {{A modeling of singing voice robust to accompaniment sounds and its application to singer identification and vocal-timbre-similarity-based music information retrieval}},
volume = {18},
year = {2010}
}
@article{Li2010,
abstract = {In this paper, we present a music information retrieval system which enables users to retrieve music by vocal query. Three essential components are query processing, database construction by MIDI and an approximate search engine. For query processing, we have achieved a real-time and robust voice-to- melody converter. For database construction, proposed MIDI analysis methods to obtain music melody features from MIDI files automatically. In order to match query with melodies in database, we extend an existing search engine into a fast approximate melodic matching engine. We have carried out extensive experiments on the prototype system to evaluate the performance. The results show that the proposed three components are achieving good performance.},
annote = {Estudar novamente o artigo, mas aperesenta uma verifica{\c{c}}{\~{a}}o de similaridade via Logica Fuzzy e Constru{\c{c}}{\~{a}}o de Dataset.
Chaves: 
Music Datasets
Music Similarity
Fuzzy
Features Extraction},
author = {Li, Peng and Zhou, Mingquan and Wang, Xuesong and Wang, Xiaofeng and Li, Nansha and Xie, Lizhi},
doi = {10.1109/ICCAE.2010.5452008},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2010 - A novel MIR framework and application with automatic voice processing, database construction and fuzzy matching.pdf:pdf},
isbn = {9781424455850},
journal = {2010 The 2nd International Conference on Computer and Automation Engineering, ICCAE 2010},
keywords = {"Cabinet" post-treatment,MIR,Melodic matching,Pitch extraction,Vocal query},
pages = {20--24},
title = {{A novel MIR framework and application with automatic voice processing, database construction and fuzzy matching}},
volume = {1},
year = {2010}
}
@article{MartinsdeSousa2016,
annote = {Apesar de focar em Machine Learning para montagem de generos musicais, o artigo {\'{e}} muito interessante, apresenta codigo e as bases utilizadas e vem de brasileiros fazendo pesquisa em MIR. Vale a pena verificar o framework utilizado para feature extraction, j{\'{a}} que para as features simbolicas estou utilizando o JSymbolic, mas para extender em audio seria interessante ver pois {\'{e}} em C++
Chaves: 
Music Datasets
Audio Processing
Source Code
Machine Learning},
author = {{Martins de Sousa}, Jefferson and {Torres Pereira}, Eanes and {Ribeiro Veloso}, Luciana},
doi = {10.1109/ICDSP.2016.7868526},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martins de Sousa, Torres Pereira, Ribeiro Veloso - 2016 - A robust music genre classification approach for global and regional music dat.pdf:pdf},
isbn = {978-1-5090-4165-7},
journal = {2016 IEEE International Conference on Digital Signal Processing (DSP)},
pages = {109--113},
title = {{A robust music genre classification approach for global and regional music datasets evaluation}},
url = {http://ieeexplore.ieee.org/document/7868526/},
year = {2016}
}
@article{JoanSerra2008,
abstract = {Nowadays, the term cover song (or simply cover) can mean any new version, performance, rendition, or recording of a previously recorded track. Cover song identification is a task that has received increased popularity in the Music Information Retrieval (MIR) com- munity in recent years, as it provides a direct and objective way for evaluating music similarity. In this paper, we propose a new method for determining the similarity between tonal sequences and, there- fore, for identifying cover songs. This is based on a novel chroma similarity measure, and on a newly developed dynamic program- ming local alignment technique. Results confirm that the perfor- mance of the proposed system is significantly superior to other state- of-the-art approaches (more than 57{\%} better)},
annote = {Artigo important{\'{i}}ssimo de se ter na lista de referencias, Utiliza uma abordagem geometrica e de cadeias de caracteres.

Chaves:
Music Similarity
Smith Waterman SW
Chromagraph
Hybrid},
author = {{Joan Serra}, Emilia Gomez},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Joan Serra - 2008 - Audio Cover Song Identification Based on Tonal Sequence Alignment.pdf:pdf},
isbn = {1424414849},
journal = {IEEE 2008},
pages = {61--64},
title = {{Audio Cover Song Identification Based on Tonal Sequence Alignment}},
year = {2008}
}
@article{Jang2011,
abstract = {This paper proposes a matching engine of a query-by-singing/ humming (QbSH) system of which database is constructed from polyphonic recordings such as MP3 files. Use of the database makes the system more practical since it saves the trouble of gathering MIDI files. The pitch sequences tran? scribed from polyphonic recordings may have errors, and to reduce the influence of the errors, the matching engine uses chroma-scale representation, compensation, and asymmetric dynamic time warping. We propose the use of saturated dis? tances, and it is verified that the distances perform better then generally-used absolute difference and squared difference. In our experiment, our QbSH system achieved mean recipro? cal rank of 0.725 for 1000 singing/ humming queries when searching from a database of 28 hour audio data},
annote = {Artigo interessante, apresenta o algoritmo DTW passo a passo e as etapas bem explicadas do QBH
Chaves:
geometric-representation
Measure Evaluation},
author = {Jang, Dalwon and Song, Chai Jong and Shin, Saim and Park, Sung Joo and Jang, Sei Jin and Lee, Seok Pil},
doi = {10.1109/ISSPIT.2011.6151570},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalwon Jang, Chai-Jong Song, Saim Shin, Sung-Joo Park, Sei-Jin Jang - 2011 - Implementation of a matching engine for a practical query-b.pdf:pdf},
isbn = {9781467307529},
journal = {IEEE International Symposium on Signal Processing and Information Technology, ISSPIT 2011},
keywords = {Query-by-singing/humming,Sequence matching,distance,dynamic time warping,matching engine},
number = {i},
pages = {258--263},
title = {{Implementation of a matching engine for a practical query-by-singing/ humming system}},
year = {2011}
}
@article{Khan2011,
abstract = {Songs are considered the major source of entertainment for the people of all age groups. With the wide spread growth of World Wide Web. Various resources are available and accessible. The high availability of audio music content is bringing significant problems and the relevant songs retrieval being the foremost. Searching of audio files on the basis of its content is the most effective way, especially in the case when supportive information (metadata information) of the file is missing or incomplete. In this paper, we aim to discuss the famous content based searching technique, Query by Humming (QbH) along-with the other existing techniques in the domain. We have highlighted certain open issues and key challenges that need to be address by the research community for the advancement in the domain. The discussion is supported by conducting surveys to study the importance of these highlighted issues for the relevant songs retrial.},
annote = {Artigo muitissimo importante e relevante, fala das dificuldades relacionadas a um sistema QBH, e cont{\'{e}}m uma descri{\c{c}}{\~{a}}o geral das tecnicas, inclusive inclui a representa{\c{c}}{\~{a}}o por string como uma op{\c{c}}{\~{a}}o(Onde {\'{e}} convertido dados simbolicos em audio - Caminho inverso do QBP)
Chaves: 
state of the art},
author = {Khan, Nauman Ali and Mushtaq, Mubashar},
doi = {10.1109/ICADIWT.2011.6041417},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan, Mushtaq - 2011 - Open issues on query by humming.pdf:pdf},
isbn = {9781424498246},
journal = {4th International Conference on the Applications of Digital Information and Web Technologies, ICADIWT 2011},
keywords = {Query by humming},
pages = {147--152},
title = {{Open issues on query by humming}},
year = {2011}
}
@article{Perraudin2018,
abstract = {IEEE We present a novel method for the compensation of long duration data loss in audio signals, in particular music. The concealment of such signal defects is based on a graph that encodes signal structure in terms of time-persistent spectral similarity. A suitable candidate segment for the substitution of the lost content is proposed by an intuitive optimization scheme and smoothly inserted into the gap, i.e. the lost or distorted signal region. Extensive listening tests show that the proposed algorithm provides highly promising results when applied to a variety of real-world music signals.},
annote = {Artigo interessant{\'{i}}ssimo , pois aborda a estrutura geral de como o algoritmo esta implementado no QBPLab (Convolution Kenels) , vindos de processamento de imagens, porem neste caso esta sendo criado um grafo de similaridade da propria musica para a realiza{\c{c}}{\~{a}}o de restaura{\c{c}}{\~{a}}o de audio.
N{\~{a}}o esta sendo utilizado nenhum algoritmo de similaridade, na realidade o grafo de similaridade esta sendo criado assim, pois esta se criando um grafo com as frequencias mais proximas e assim identificando gaps no grafo.
Implementei Pathfinding usando a mesma abordagem e funcionou muito bem!
Chaves: 
Music Similarity
Similarity Graphs},
author = {Perraudin, Nathanael and Holighaus, Nicki and Majdak, Piotr and Balazs, Peter},
doi = {10.1109/TASLP.2018.2809864},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Perraudin et al. - 2018 - Inpainting of long audio segments with similarity graphs.pdf:pdf},
issn = {23299290},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
number = {6},
pages = {1083--1094},
title = {{Inpainting of long audio segments with similarity graphs}},
volume = {26},
year = {2018}
}
@article{Sawata2017,
abstract = {A novel audio feature projection using Kernel Discriminative Locality Preserving Canonical Correlation Analysis (KDLPCCA)-based correlation with electroencephalogram (EEG) features for favorite music classification is presented in this paper. The projected audio features reflect individual music preference adaptively since they are calculated by considering correlations with the user's EEG signals during listening to musical pieces that the user likes/dislikes via a novel CCA proposed in this paper. The novel CCA, called KDLPCCA, can consider not only a non-linear correlation but also local properties and discriminative information of each class sample, namely, music likes/dislikes. Specifically, local properties reflect intrinsic data structures of the original audio features, and discriminative information enhances the power of the final classification. Hence, the projected audio features have an optimal correlation with individual music preference reflected in the user's EEG signals, adaptively. If the KDLPCCA-based projection that can transform original audio features into novel audio features is calculated once, our method can extract projected audio features from a new musical piece without newly observing individual EEG signals. Our method therefore has a high level of practicability. Consequently, effective classification of user's favorite musical pieces via a Support Vector Machine (SVM) classifier using the new projected audio features becomes feasible. Experimental results show that our method for favorite music classification using projected audio features via the novel CCA outperforms methods using original audio features, EEG features and even audio features projected by other state-of-the-art CCAs.},
annote = {Artigo interessante para Machine Learning aplicado a MIR.
Chaves: 
statistical},
author = {Sawata, Ryosuke and Ogawa, Takahiro and Haseyama, Miki},
doi = {10.1109/TAFFC.2017.2729540},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sawata, Ogawa, Haseyama - 2017 - Novel Audio Feature Projection Using KDLPCCA-based Correlation with EEG Features for Favorite Music Cla.pdf:pdf},
issn = {19493045},
journal = {IEEE Transactions on Affective Computing},
keywords = {Correlation,Electroencephalogram (EEG),Electroencephalography,Feature extraction,Multiple signal classification,Music,Recommender systems,Support vector machines,canonical correlation analysis (CCA),kernel method,locality preservation,music liking/disliking,support vector machine (SVM)},
number = {JUNE 2016},
pages = {1--14},
title = {{Novel Audio Feature Projection Using KDLPCCA-based Correlation with EEG Features for Favorite Music Classification}},
volume = {3045},
year = {2017}
}
@article{Su2014,
abstract = {There has been an increasing attention on learning feature representations from the complex, high-dimensional audio data applied in various music information retrieval (MIR) problems. Unsupervised feature learning techniques, such as sparse coding and deep belief networks have been utilized to represent music information as a term-document structure comprising of elementary audio codewords. Despite the widespread use of such bag-of-frames (BoF) model, few attempts have been made to systematically compare different component settings. Moreover, whether techniques developed in the text retrieval community are applicable to audio codewords is poorly understood. To further our understanding of the BoF model, we present in this paper a comprehensive evaluation that compares a large number of BoF variants on three different MIR tasks, by considering different ways of low-level feature representation, codebook construction, codeword assignment, segment-level and song-level feature pooling, tf-idf term weighting, power normalization, and dimension reduction. Our evaluations lead to the following findings: 1) modeling music information by two levels of abstraction improves the result for difficult tasks such as predominant instrument recognition, 2) tf-idf weighting and power normalization improve system performance in general, 3) topic modeling methods such as latent Dirichlet allocation does not work for audio codewords.},
annote = {Focado em Aprendizagem de M{\'{a}}quina , este artigo aborda a tecnica de Bag of Frames.
Chaves: 
Machine Learning
Bag of Frames},
author = {Su, Li and Yeh, Chin Chia Michael and Liu, Jen Yu and Wang, Ju Chiang and Yang, Yi Hsuan},
doi = {10.1109/TMM.2014.2311016},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Su et al. - 2014 - A systematic evaluation of the bag-of-frames representation for music information retrieval.pdf:pdf},
isbn = {1520-9210 VO - 16},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Bag-of-frames model,music information retrieval,sparse coding,unsupervised feature learning},
number = {5},
pages = {1188--1200},
title = {{A systematic evaluation of the bag-of-frames representation for music information retrieval}},
volume = {16},
year = {2014}
}
@article{Liu2014,
abstract = {When a user cannot remember the title ofa song, or its related details, the most direct and convenientmethodtosearchfor the song is by humming a section of it. This search method is par- ticularly important when a user does not have access to operate the audio device. The design methodology used in conventional search mechanisms that query by singing/humming, commonly empha- size signal processing or music comparison. The background of the user often influences the genres of the songs being searched, and this is an area of research seldom studied. In our study, we use the information from a user's search history, as well as the properties of genres common to users with similar backgrounds, to estimate the genre or style the current user may be interested in based on a probability calculation. The accuracy from querying by singing/humming is improved. Our method can be divided into two phases. In the first phase, we find the possible search results. This is similar to the conventional singing/humming query process. During the second phase, the musical preference of the user is uti- lized to rank the possible search results again. Songs that are most likely to be queried would be positioned at the front of the list in the search results. Through our experiments, significant improve- ment is demonstrated with our method.},
annote = {Mantido por conter varias compara{\c{c}}{\~{a}}o de varios metodos de QBH.
Chaves: 
Music Similarity
Measure Evaluation},
author = {Liu, Ning-Han},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu - 2014 - Effective Results Ranking for Mobile Query by Singing Humming Using a Hybrid Recommendation Mechanism.pdf:pdf},
number = {5},
pages = {1407--1420},
title = {{Effective Results Ranking for Mobile Query by Singing / Humming Using a Hybrid Recommendation Mechanism}},
volume = {16},
year = {2014}
}
@article{Wang2014,
abstract = {This study presents a discussion on the task of score alignment, which properly aligns an audio recording with its corresponding score. Conventional methods have difficulty performing this task because of asynchrony in the recording of simultaneous notes in the score. A note-based score alignment based on the pitch-by-time feature is proposed, called the piano-roll feature, and it presents an approach for converting the audio spectrogram to a piano-roll-like feature. Score-driven non-negative matrix factorisation is then adopted in the transformation. Furthermore, this study also proposes pitch-wise alignment considering each pitch sequence (i.e. the row of piano roll) separately. Results based on the MIDI-Aligned Piano Sounds database show that approximately 88{\%} of notes match their onsets, deviating from the ground truth by less than 50 ms. Other results based on SCREAM Music Annotation Project database that is a manual annotation project of commercial CD recordings are presented as well.},
annote = {Artigo importante em estar na lista de artigos relevantes, fala sobre o Piano Roll e a separa{\c{c}}{\~{a}}o nota por nota no tempo de arquivos de audio, relativo ao Chromagrama.
Funcionalidade que {\'{e}} apenas atendida pelo algoritmo (Porem em faixas monof{\^{o}}nicas).
Palavras Chave:
Music Similarity
DTW
Piano Roll
Chromagram
Matrix Factorization
geometric-representation},
author = {Wang, Tien-Ming and Tsai, Pei-Yin and Su, Alvin Wen-Yu},
doi = {10.1049/iet-spr.2012.0157},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Tsai, Su - 2014 - Note-based alignment using score-driven non-negative matrix factorisation for audio recordings.pdf:pdf},
isbn = {1751-9683},
issn = {17519675},
journal = {IET Signal Processing},
number = {1},
pages = {1--9},
title = {{Note-based alignment using score-driven non-negative matrix factorisation for audio recordings}},
url = {http://digital-library.theiet.org/content/journals/10.1049/iet-spr.2012.0157},
volume = {8},
year = {2014}
}
@article{Shen2009,
abstract = {In this paper, we introduce a novel indexing scheme-query context$\backslash$ntree (QUC-tree) to facilitate efficient query sensitive music search$\backslash$nunder different query contexts. Distinguished from the previous approaches,$\backslash$nQUC-tree is a balanced multiway tree structure, where each level$\backslash$nrepresents the data space at different dimensionality. Before the$\backslash$ntree structure construction, principle component analysis (PCA) is$\backslash$napplied for data analysis and transforming the raw composite features$\backslash$ninto a new feature space sorted by the importance of acoustic features.$\backslash$nThe PCA transformed data and reduced dimensions in the upper levels$\backslash$ncan alleviate suffering from dimensionality curse. To accurately$\backslash$nmimic human perception, an extension called QUC +-tree is proposed,$\backslash$nwhich further applies multivariate regression and EM based algorithm$\backslash$nto estimate the weight of each individual feature. The comprehensive$\backslash$nextensive experiments to evaluate the proposed structures against$\backslash$nstate-of-art techniques based on different datasets. The experimental$\backslash$nresults demonstrate the superiority of our technique.},
annote = {Artigo Muito Interessante, foca em Indexa{\c{c}}{\~{a}}o do dataset musical em arvore para otimiza{\c{c}}{\~{a}}o da lista de musicas a ser comparada pelos algoritmos.
Esta {\'{e}} uma ideia que surgiu durante o desenvolvimento do Dataset do QBPLab , portanto vou inclui-lo na base para futuros estudos.
Chaves: 
Music Datasets
Music Similarity
QUC-Tree Query Context Tree},
author = {Shen, Jialie and Tao, Dacheng and Li, Xuelong},
doi = {10.1109/TMM.2008.2009719},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen, Tao, Li - 2009 - QUC-tree Integrating query context information for efficient music retrieval.pdf:pdf},
isbn = {1520-9210},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Indexing structure,KNN,Music,QUC-tree,Similarity query},
number = {2},
pages = {313--323},
title = {{QUC-tree: Integrating query context information for efficient music retrieval}},
volume = {11},
year = {2009}
}
@article{Robine2007,
abstract = {Estimating the symbolic music similarity is one of the major open problems in the music information retrieval research domain. Existing systems consider sequences of notes characterized by pitches and durations. Similarity estimation is mainly based on variations of pitches and durations and does not consider any other musical elements. However, musical elements such as tonality or rhythm are particularly important in the perception of music. In this paper we propose to investigate some algorithmic improvements that allow edit-based systems to take into account important musical elements: tonality, passing notes, strong and weak beats. These elements are illustrated with a few monophonic musical examples which lead to important errors in usual systems. First experiments with these examples show that the improvements induced are significant. Furthermore, experimental results obtained with the MIREX 2005 database are very good. All the results are thus very promising since they confirm that considering musical information improves the accuracy of music retrieval systems. Copyright 2007 ACM.},
annote = {Artigo Extremamente relevante para o Mestrado.
Mostra implementa{\c{c}}{\~{a}}o Hibrida do Edit-Distance para calculo de similaridade.
Chaves: 
string-matching},
author = {Robine, Matthias and Hanna, Pierre and Ferraro, Pascal},
doi = {10.1145/1290082.1290103},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Robine, Hanna, Ferraro - 2007 - Music Similarity Improvements of Edit-based Algorithms by Considering Music Theory.pdf:pdf},
isbn = {9781595937780},
journal = {Proceedings of the international workshop on Workshop on multimedia information retrieval - MIR '07},
number = {February},
pages = {135},
title = {{Music Similarity: Improvements of Edit-based Algorithms by Considering Music Theory}},
url = {http://portal.acm.org/citation.cfm?doid=1290082.1290103},
year = {2007}
}
@article{Huang2015,
abstract = {Query-by-Humming involves retrieving music with a melody that matches the hummed query. An improved Query-by-Humming system for extracting pitch contour information based on a fuzzy inference model is introduced. In addition, an improved content-based music repeating pattern extraction model is introduced. Our bar-indexing method can extract the melody, identify repeating patterns and handle polyphonic MIDI files. To verify the effectiveness of the system, 15 volunteers recorded queries that were fed as input to the system and the longest common subsequence (LCS) was used to identify the most related top N matches. The system achieves 70{\%} accuracy among the top 5 items retrieved.},
annote = {Artigo muito Interessante, o autor explica a relevancia e a origem das features utilizadas para identifica{\c{c}}{\~{a}}o da similaridade, e propoe um sistema Fuzzy para a identifica{\c{c}}{\~{a}}o.Artigo de 2015 bem atual pois {\'{e}} a primeira ocorrencia de Fuzzy em Music Similarity que coletei.
Chaves
Music Similarity
Features Extraction
Fuzzy
State of the Art},
author = {Huang, Yo Ping and Lai, Shin Liang and Sandnes, Frode Eika},
doi = {10.1016/j.asoc.2015.04.011},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Lai, Sandnes - 2015 - A repeating pattern based Query-by-Humming fuzzy system for polyphonic melody retrieval.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Content-based music information retrieval,Fuzzy inference system,Pitch contour,Query-by-Humming,Repeating pattern},
pages = {197--206},
publisher = {Elsevier B.V.},
title = {{A repeating pattern based Query-by-Humming fuzzy system for polyphonic melody retrieval}},
url = {http://dx.doi.org/10.1016/j.asoc.2015.04.011},
volume = {33},
year = {2015}
}
@article{Barrington2009,
abstract = {In this paper, we consider representing a musical signal as a dynamic texture, a model for both the timbral and rhythmical qualities of sound. We apply the new representation to the task of automatic song segmentation. In particular, we cluster sequences of audio feature-vectors, extracted from the song, using a dynamic texture mixture model (DTM). We show that the DTM model can both detect transition boundaries and accurately cluster coherent segments. The similarities between the dynamic textures which define these segments are based on both timbral and rhythmic qualities of the music, indicating that the DTM model simultaneously captures two of the important aspects required for automatic music analysis.},
annote = {UAAAU!!!
Artigo falando sobre representa{\c{c}}{\~{a}}o em imagem do som para identifica{\c{c}}{\~{a}}o de similaridade utilizando tecnicas de vis{\~{a}}o computacional.
Extremamente relevante para o estado da Arte.

Chaves:
Music Similarity
DTM Dinamic Mixture Model},
author = {Barrington, Luke and Chan, Antoni B and Lanckriet, Gert},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrington, Chan, Lanckriet - 2009 - Dynamic Texture Models of Music.pdf:pdf},
isbn = {9781424423545},
number = {1},
pages = {1589--1592},
title = {{Dynamic Texture Models of Music}},
year = {2009}
}
@article{Sekhar2017,
abstract = {In this paper, we present an approach to transcription of varnams in Carnatic music using hidden Markov models (HMMs). We draw upon domain-specific information in that we build raga-specific HMMs and use rhythmic cycle (ta?a) information in the initialization of the HMMs and in the postprocessing of the output. The ground truth is obtained from standard notations of varnams. Transcription performance on varnams in eight ragas is presented. Since the extant notation for Carnatic music is incomplete when it comes to gamakas (melodic ornamentations), the results are interpreted accordingly. Significantly, they point to the possibility of a rich transcription for Carnatic music, which is an unsolved problem in the automatic processing of Indian music.},
annote = {Artigo importantissimo de se ter na base, apesar de focar em Query By Humming, ele apresenta uma abordagem baseada em regras musicais que vale a pena um estudo mais detalhado.

Chaves: 
statistical},
author = {Sekhar, P V Krishnaraj and Viraraghavan, Venkata S and Sankaran, Sridharan and Murthy, Hema A},
doi = {10.1109/NCC.2017.8077057},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sekhar et al. - 2017 - An approach to transcription of varnams in Carnatic music using hidden Markov models.pdf:pdf},
isbn = {978-1-5090-5356-8},
journal = {2017 Twenty-third National Conference on Communications (NCC)},
pages = {1--6},
title = {{An approach to transcription of varnams in Carnatic music using hidden Markov models}},
url = {http://ieeexplore.ieee.org/document/8077057/},
year = {2017}
}
@article{West2010,
abstract = {We address the problem of estimating automatically from audio signals the similarity between two pieces of music, a technology that has many applications in the online digital music industry. Conventional methods of audio music search use distance measures between features derived from the audio for this task. We describe three techniques that make use of music classifiers to derive representations of audio features that are based on cultur- ally motivated information learned by the classifier. When these representations are used for similarity estimation, they produce very significant reductions in computational complexity over ex- isting techniques (such as those based on the KL-Divergence), and also produce metric similarity spaces, which facilitate the use of technologies for the sub-linear scaling of search times. We have evaluated each system using both pseudo-objective techniques and human listeners, and we demonstrate that this efficiency gain is obtained while providing a comparable level of performance when compared with existing techniques.},
annote = {Artigo Muito interessante usa Machine Learning para extrair features relevantes e definir um espa{\c{c}}o de similaridade geral da musica.
Ap{\'{o}}s ter definido as features ideais {\'{e}} aplicado distancia sobre elas para verificar a similaridade.
Esta {\'{e}} a ideia basica das melhorias de evolu{\c{c}}{\~{a}}o do algoritmo que estou estudando para o projeto, portanto incluido na lista de referancias para futura corrobora{\c{c}}{\~{a}}o.
Chaves: 
Machine Learning
Features Extraction
Music Similarity},
author = {West, Kris and Cox, Stephen and Member, Senior},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/West, Cox, Member - 2010 - Into Audio Music Similarity Estimation.pdf:pdf},
journal = {Ieee Transactions On Audio Speech And Language Processing},
number = {3},
pages = {625--637},
title = {{Into Audio Music Similarity Estimation}},
volume = {18},
year = {2010}
}
@article{Wang2015,
annote = {Artigo Extremamente Relevante, pois a id{\'{e}}ia de se criar o DTW Tridimensional , segue a mesma linha do que est{\'{a}} sendo feito no QBPLab com a proposta do Mestrado que {\'{e}} uma Implementa{\c{c}}{\~{a}}o Hibrida.
No caso deste artigo a similaridade esta sendo aplicada para identificar assincronicidades entre as faixas polifonicas!!! Uau!
Chaves: 
geometric-representation},
author = {Wang, Siying and Ewert, Sebastian and Dixon, Simon},
doi = {10.1109/ICASSP.2015.7178037},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Ewert, Dixon - 2015 - Compensating for asynchronies between musical voices in score-performance alignment.pdf:pdf},
isbn = {9781467369978},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {asynchrony,melody lead,multi-dimensional dynamic time warping,score-audio alignment},
pages = {589--593},
title = {{Compensating for asynchronies between musical voices in score-performance alignment}},
volume = {2015-Augus},
year = {2015}
}
@article{Degani2013,
abstract = {In this paper, we propose a method to integrate the results of different cover song identification algorithms into one single measure which, on the average, gives better results than ini- tial algorithms. The fusion of the different distance measures is made by projecting all the measures in a multi-dimensional space, where the dimensionality of this space is the number of the considered distances. In our experiments, we test two distance measures, namely the Dynamic Time Warping and the Qmax measure when applied in different combinations to two features, namely a Salience feature and a Harmonic Pitch Class Profile (HPCP). While the HPCP is meant to extract purely harmonic descriptions, in fact, the Salience allows to better discern melodic differences. It is shown that the combi- nation of two or more distance measure improves the overall performance.},
annote = {Artigo interessante, mostra o uso dos algoritmos de alinhamento para o calculo de score mesclados entre si para detec{\c{c}}{\~{a}}o de copia.
Mostra tambem o que foi utilizado para avaliar os resultados e a base utilizada para os testes.
Chaves: 
Music Datasets
geometric-representation},
author = {Degani, Alessio and Dalai, Marco and Leonardi, Riccardo and Migliorati, Pierangelo},
doi = {10.1109/WIAMIS.2013.6616128},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Degani et al. - 2013 - A Heuristic for Distance Fusion in Cover Song Identification.pdf:pdf},
journal = {2013 (WIAMIS)},
keywords = {cover song identification,distance fusion},
title = {{A Heuristic for Distance Fusion in Cover Song Identification}},
year = {2013}
}
@article{Kaminskas2012,
abstract = {Increasing amount of online music content has opened new opportunities for implementing new effective information access services–commonly known as music recommender systems–that support music navigation, discovery, sharing, and formation of user communities. In the recent years a new research area of contextual (or situational) music recommendation and retrieval has emerged. The basic idea is to retrieve and suggest music depending on the user's actual situation, for instance emotional state, or any other contextual conditions that might influence the user's perception of music. Despite the high potential of such idea, the development of real-world applications that retrieve or recommend music depending on the user's context is still in its early stages. This survey illustrates various tools and techniques that can be used for addressing the research challenges posed by context-aware music retrieval and recommendation. This survey covers a broad range of topics, starting from classical music information retrieval (MIR) and recommender system (RS) techniques, and then focusing on context-aware music applications as well as the newer trends of affective and social computing applied to the music domain.},
annote = {Artigo Gen{\'{e}}rico e Superficial mas aborda como um todo o eco-sistema de solu{\c{c}}{\~{o}}es e tecnicas de Pesquisa de Musicas.
Chaves: 
State of The Art},
author = {Kaminskas, M and Ricci, F},
doi = {10.1016/j.cosrev.2012.04.002},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaminskas, Ricci - 2012 - Contextual music information retrieval and recommendation State of the art and challenges.pdf:pdf},
issn = {15740137},
journal = {Computer Science Review},
keywords = {a ff ective computing,context-aware services,music information retrieval,music recommender systems,social computing},
number = {2},
pages = {89--119},
title = {{Contextual music information retrieval and recommendation: State of the art and challenges}},
volume = {6},
year = {2012}
}
@article{Mullensiefen2004,
abstract = {This paper describes the systematization, testing and optimiziation of different approaches for measuring similarities of melodies. First, a quick overview of our mathematical systematization for similarity measures, including data transformations and calculation methods is given. Behavioral data from three listener experiments is used to model experts' similarity judgments of short melodies from popular music in different contextual situations. A weighted combination of several similarity measures, representing two resp. three different sources of information, is found to explain user ratings best. As an application example one of the optimal similarity measures resulting from these three experiments is used to analyze a body of about 600 folk melodies from Luxembourg. Finally, the expert classification of the individual phrases of these melodies that has carried out in an extensive ethno-musicological study (Sagrillo, 1999) is reconstructed with the help of an optimal combination of similarity measures using logistic regression.},
annote = {Artigo Interessante, por{\'{e}}m muito Vago sobre diversas maneiras de se avaliar desempenho de algoritmos de similaridade.
Estudar de novo...
Chaves: 
Measure Evaluation},
author = {M{\"{u}}llensiefen, Daniel and Frieler, Klaus},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}llensiefen, Frieler - 2004 - Melodic Similarity Approaches and Applications.pdf:pdf},
isbn = {1876346507},
journal = {Proceedings of the 8th International Conference on Music Perception {\&} Cognition},
pages = {283--289},
title = {{Melodic Similarity: Approaches and Applications}},
url = {http://www.icmpc8.umn.edu/proceedings/ICMPC8/PDF/AUTHOR/MP040038.PDF},
year = {2004}
}
@article{Al-Taee2009,
abstract = {Unlike occidental flutes, Arabian flutes have gained only limited attention in literature over the past years. Moreover, the least tone-to-tone distance in Arabian music is only half of that of occidental music and therefore the analysis and features extraction process of Arabian music is more challenging. This paper investigates the tone-to-tone features of two traditional Arabian flutes; Al-Nay and Shabbaba. These two kinds of flute gain wide popularity in the Middle Eastern and North African countries. A previously reported analysis and features extraction package is adapted and used for query-by --playing melody retrieval. Experimental tone-to-tone investigations based on the Discrete Fourier Transform (DFT) are presented for both flutes. The obtained results showed that the analysis approach is robust and successfully performed the task of query-by--playing melody retrieval. Comparison results for Al-Nay and Shabbaba were obtained and evaluated using the Arabian musical Scale "Bayat", as a reference. [ABSTRACT FROM AUTHOR]},
annote = {Artigo muito interessante pois mostra o processo completo de transformar a musica em audio em musica simbolica MIDI.
Uma pena que no momento de aplicar algoritmos de similaridade o autor encerrou a pesquisa apenas colocando que isto seria outro desafio... kkkk
Chaves: 
Audio Processing
Features Extraction
Music Similarity},
author = {Al-Taee, MA and Al-Ghawanmeh, Fadi M and Al-Own, Baha O. Abu},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Taee, Al-Ghawanmeh, Al-Own - 2009 - Analysis and Pattern Recognition of Woodwind Musical Tones Applied to Query-by-Playing Melody Ret.pdf:pdf},
isbn = {9789881701251},
journal = {Proceedings of the World Congress on Engineering},
pages = {1--6},
title = {{Analysis and Pattern Recognition of Woodwind Musical Tones Applied to Query-by-Playing Melody Retrieval}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.6002{\&}rep=rep1{\&}type=pdf},
volume = {I},
year = {2009}
}
@article{Park2013,
abstract = {Since numerous songs have recently been released increasingly, the genre of the song clustering is reasonably more important in terms of the audience's choice. Also arguments for plagiarism are continuously being raised. For this reason, similarity measurement between two songs is important. In previous works, although similarity measurement has been actively researched in the field of query by humming, they only focused on quite partial matching for input humming. To solve this problem, we proposed a novel similarity measurement method between two songs. The proposed method has several advantages compared with previous works. Firstly, it is possible to measure overall similarity between two different songs. Secondly, overall region of a song is represented as 1-dimensional signal which can be obtained by run-length representation of 2-dimensional note information ((pitch, duration)). Thirdly, by sequentially adopting median filter, average filter, Z-score normalization into the 1-dimensional signal, we obtain the overall flow without noise feature such as the eccentric note of the song. Lastly, a new distance metric namely the conditional Euclidean distance is used by combining two distance concepts such as the Euclidean distance and the Hamming distance. To perform the feasibility test, several famous songs by the Beatles and the MIREX'08 dataset were used for our experiment. Also, by applying our method into a comparison between two songs with a plagiarism issue, we confirmed that very high similarity score between the two songs was measured.},
annote = {Artigo Muito Relevante e aborda uma das tecnicas que pretendo usar no Mestrado para a implementa{\c{c}}{\~{a}}o Hybrid do algoritmo de Similaridade.
Chaves: 
Measure Evaluation
string-matching},
author = {Park, Min Woo and Lee, Eui Chul},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Lee - 2013 - Similarity measurement method between two songs by using the conditional euclidean distance.pdf:pdf},
issn = {17900832},
journal = {WSEAS Transactions on Information Science and Applications},
keywords = {Music clustering,Music plagiarism,Music similarity measurement},
number = {12},
pages = {381--388},
title = {{Similarity measurement method between two songs by using the conditional euclidean distance}},
volume = {10},
year = {2013}
}
@article{Yu2007,
abstract = {Content-based audio information retrieval is one of the most interesting and fast-growing research areas. Suitable feature sets can help to reduce the tedious computation time and speed up retrieval. In this paper we report a study of the music spectral properties aimed at the acoustic-based music data similarity measurement and show that the spectral features of adjacent frames are highly correlated. Based on such a case study we mainly focus on making an evaluation of feature choice in the three aspects: storage, computation and retrieval ratio. The extensive evaluations confirm the effectiveness of feature merge in quickening sequence matching for query-by-content audio retrieval and show that MFCC with feature merge is the best tradeoff among storage requirement, computation cost and retrieval ratio.},
annote = {Artigo muito interessante de se ter como referencia , pois fala exclusivamente do papael da Extra{\c{c}}{\~{a}}o de Features na busca por similaridade.
Interessante como o artigo ficou somente na extra{\c{c}}{\~{a}}o das features e n{\~{a}}o extendeu para a verifica{\c{c}}{\~{a}}o de similaridade com algoritmos(Ser{\'{a}} que faltou tempo???)
Chaves: 
Music Similarity
Feature Extraction},
author = {Yu, Yi and Downie, J. Stephen and Joe, Kazuki},
doi = {10.1109/ISMW.2007.4475986},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Downie, Joe - 2007 - An evaluation of feature extraction for query-by-content audio information retrieval.pdf:pdf},
isbn = {0769530842},
journal = {Proceedings ISM Workshops 2007 9th IEEE International Symposium on Multimedia - Workshops},
number = {2},
pages = {297--302},
title = {{An evaluation of feature extraction for query-by-content audio information retrieval}},
year = {2007}
}
@article{Duong2016,
abstract = {Single-channel source separation is an approach to decompos- ing a single-channel recording into its sources without un- derstanding how the sources are mixed. This work develops a sparse regularized nonnegative matrix factorization scheme with spatial dispersion penalty (SpaSNMF). To preserve spatial locality structured information on the basis for sound source separation, intra-sample structure constraints that are learnt from the input data are utilized. Based on the hypothesis that ad- jacent spectrogram points should not be dispersed in basis spec- tra, this framework is provided for supervised source separation. To improve the separation performance, group sparse penalties are simultaneously constructed. A multiple-update-rule opti- mization scheme was used to solve the objective function of the proposed SpaSNMF. Experiments on single-channel source separation reveal that the proposed method provides more ro- bust basis factors and achieves better results than standard NMF and its extensions.},
annote = {Palavras Chave
statistical},
author = {Duong, Viet-hang and Lee, Yuan-shan and Pham, Bach-tung and Mathulaprangsan, Seksan and Bao, Pham-the and Wang, Jia-ching},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Duong et al. - 2016 - Spatial Dispersion Constrained NMF for Monaural Source Separation.pdf:pdf},
isbn = {9781509042944},
journal = {IEEE},
number = {1},
title = {{Spatial Dispersion Constrained NMF for Monaural Source Separation}},
volume = {0},
year = {2016}
}
@article{Ali2014,
abstract = {Music has always been the vital part of entertainment. Musical schools and singing reality shows are very popular and have become an integral part of our daily life. They provide entertainment to the viewers and a platform to the willing contestants to show their talent. This paper introduces the idea for evaluating the performance of singers using melodic pattern matching techniques, namely LBDM (Local Boundary Detection Model) and DTW (Dynamic Time Warping) based on peaks extracted from the strength and pitches of the audio signal respectively. The audio corpus both standard and recorded song track from singer is maintained using SQL database consist of 5 different song track in MP3 format with duration of approximately 2.10 minutes. The experimental analysis provide the following observation from the comparison between LBDM and DTW with similar and different track singer in term of percentage efficiency; LBDM shows 99.99{\%} matching and DTW shows 99.16{\%} matching, whereas LBDM shows 45.89{\%} matching and DTW shows 55.8{\%} matching with similar and different track singers respectively. The experimental results clearly evident that LBDM provides significant results as compared to DTW.},
annote = {Artigo importante! 
Chaves: 
Audio Processing
Features Extraction
Measure Evaluation
geometric-representation},
author = {Ali, Syed Abbas and Siddiqui, Aisha and Fatima, Tahura and Barkat, Javeria},
doi = {10.1109/INMIC.2014.7097337},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ali et al. - 2014 - Comparative analysis of melodic pattern matching techniques for performance evaluation of singer.pdf:pdf},
isbn = {978-1-4799-5754-5},
journal = {17th IEEE International Multi Topic Conference 2014},
keywords = {Algorithm design and analysis,Computational modeling,DTW technique,Feature extraction,Heuristic algorithms,LBDM technique,Music,Pattern matching,SQL database,Standards,Structured Query Languages,audio signal,audio signal processing,dynamic time warping,local boundary detection model,melodic pattern matching technique,music,musical schools,pattern matching,singer performance evaluation,singing reality shows},
pages = {200--204},
title = {{Comparative analysis of melodic pattern matching techniques for performance evaluation of singer}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7097337},
year = {2014}
}
@article{Page2017,
abstract = {In this paper we follow a Linked Data approach to build a layered digital library based on content from the Internet Archive Live Mu- sic Archive. Starting from the recorded audio and basic information in the Archive, we first deploy a layer of catalogue metadata which allows an initial – if imperfect – consolidation of performer, song, and venue information. A processing layer extracts audio features from the original recordings, workflow provenance, and summary feature metadata. A further analysis layer provides tools for the user to combine audio and feature data, discovered and reconciled using interlinked catalogue and feature metadata from layers below.},
annote = {Artigo Importante, pois fala de databases que podem ser utilizadas em MIR.
Chaves: 
Music Datasets},
author = {Page, Kevin R and Bechhofer, Sean},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Page, Bechhofer - 2017 - Realising a Layered Digital Library.pdf:pdf},
isbn = {9781538638613},
journal = {IEEE},
keywords = {computational audio analysis,implementation,libraries,linked data,music digital libraries,scholarly investigation using digital},
title = {{Realising a Layered Digital Library}},
year = {2017}
}
@article{Sturm2014,
abstract = {A decade has passed since the first review of research on a “flagship application” of music information retrieval (MIR): the problem of music genre recognition (MGR). During this time, about 500 works addressing MGR have been published, and at least 10 campaigns have been run to evaluate MGR systems, which makes MGR one of the most researched areas of MIR. So, where does MGR lie now? We show that in spite of this massive amount of work, MGR does not lie far from where it began, and the paramount reason for this is that most evaluation in MGR lacks validity. We perform a case study of all published research using the most- used benchmark dataset in MGR during the past decade: GTZAN. We show that none of the evaluations in these many works is valid to produce conclusions with respect to recognizing genre, i.e., that a system is using criteria relevant to recognize genre. In fact, the problems of validity in evaluation also affect research in music emotion recognition and autotagging. We conclude by discussing the implications of our work for MGR and MIR in the next ten years.},
annote = {Acho que peguei um draft....muito esquisito este artigo...mas fala de varias coisas importantes.},
archivePrefix = {arXiv},
arxivId = {1306.1461},
author = {Sturm, Bob L.},
doi = {10.1080/09298215.2014.894533},
eprint = {1306.1461},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sturm - 2014 - The State of the Art Ten Years After a State of the Art Future Research in Music Information Retrieval.pdf:pdf},
issn = {17445027},
journal = {Journal of New Music Research},
keywords = {databases,information retrieval,machine learning,music analysis},
number = {2},
pages = {147--172},
title = {{The State of the Art Ten Years After a State of the Art: Future Research in Music Information Retrieval}},
volume = {43},
year = {2014}
}
@article{Suzuki2017,
abstract = {Mathematical documents are used for mathematical communica- tion such as a math paper and discussion in an online Q{\&}A com- munity. Mathematical documentcategorization (MDC) is the task of classifying mathematical documents into mathematical categories, e.g., probability theory and set theory. This is an important task for supporting user search in recent widespread digital libraries and archiving services. Although Mathematical expressions (MEs) in the document can provide essential information for categoriza- tion, especially in math fields, using MEs for MDC has not been de- veloped. In this paper, we propose a classification method based on text combined with structures ofMEs, which are assumed to reflect conventions and rules specific to a category. We also present doc- ument collections built for evaluating MDC systems, with inves- tigation of category settings and their statistics. We demonstrate classification results, and our proposed method outperforms exist- ing methods with state-of-the-art ME modeling on F-measures.},
annote = {Artigo Extremamente importante de se manter na lista de referencias, fala sob perspectiva matem{\'{a}}tica (Mathematical Information Retrieval) a tecnica de Convolution Kernels adotada na implementa{\c{c}}{\~{a}}o do algoritmo Smith Waterman do QBPLab.

Pela data do artigo mostra que a implementa{\c{c}}{\~{a}}o adotada por mim talvez seja um Estado da Arte em Si, pois at{\'{e}} o momento n{\~{a}}o encontrei nenhum artigo mostrando implementa{\c{c}}{\~{a}}o assim(huhuuu!!!).

Chaves: 
Geometric Space
Convolution Kernels
Smith Waterman SW},
author = {Suzuki, Tokinori and Fujii, Atsushi},
doi = {10.1109/JCDL.2017.7991566},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Suzuki, Fujii - 2017 - Mathematical Document Categorization with Structure of Mathematical Expressions.pdf:pdf},
isbn = {9781538638613},
issn = {15525996},
journal = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries},
keywords = {Document categorization,Mathematical document,SVM,Structural kernel,classification},
number = {Mdc},
title = {{Mathematical Document Categorization with Structure of Mathematical Expressions}},
year = {2017}
}
@article{Joder2008,
abstract = {Nowadays, it appears essential to design automatic in- dexing tools which provide meaningful and efficient means to de- scribe the musical audio content. There is in fact a growing in- terest for music information retrieval (MIR) applications amongst which the most popular are related to music similarity retrieval, artist identification, musical genre or instrument recognition. Cur- rent MIR-related classification systems usually do not take into ac- count the mid-term temporal properties of the signal (over several frames) and lie on the assumption that the observations of the fea- tures in different frames are statistically independent. The aim of this paper is to demonstrate the usefulness of the information car- ried by the evolution of these characteristics over time. To that pur- pose, we propose a number of methods for early and late temporal integration and provide an in-depth experimental study on their interest for the task of musical instrument recognition on solo mu- sical phrases. In particular, the impact of the time horizon over which the temporal integration is performed will be assessed both for fixed and variable frame length analysis. Also, a number of re- cently proposed alignment kernels will be used for late temporal integration. For all experiments, the results are compared to a state of the art musical instrument recognition system.},
annote = {Mais um artigo de aplica{\c{c}}{\~{a}}o de Machine Learning em MIR, neste caso na identifica{\c{c}}{\~{a}}o de instrumentos Musicais.
Chaves: 
Machine Learning
Audio Processing},
author = {Joder, C and Essid, Slim and Richard, G},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Joder, Essid, Richard - 2008 - Temporal Integration for Audio Classification with Application to Musical Instrument Classification.pdf:pdf},
journal = {IEEE Transactions on Audio, Speech, and Language Processing, accepted},
number = {1},
pages = {174--186},
title = {{Temporal Integration for Audio Classification with Application to Musical Instrument Classification}},
volume = {17},
year = {2008}
}
@article{Systems2018,
abstract = {The digitization of music has seen a considerable increase in audience size from a few localized listeners to a wider range of global listeners. At the same time, the digitization brings the challenge of smoothly retrieving music from large databases. To deal with this challenge, many systems which support the smooth retrieval of musical data have been developed. At the computational level, a query music piece is compared with the rest of the music pieces in the database. These systems, music information retrieval (MIR systems), work for various applications such as general music retrieval, plagiarism detection, music recommendation, and musicology. This paper mainly addresses two parts of the MIR research area. First, it presents a general overview of MIR, which will examine the history of MIR, the functionality of MIR, application areas of MIR, and the components of MIR. Second, we will investigate music similarity measurement methods, where we provide a comparative analysis of state of the art methods. The scope of this paper focuses on comparative analysis of the accuracy and efficiency of a few key MIR systems. These analyses help in understanding the current and future challenges associated with the field of MIR systems and music similarity measures.},
annote = {Extremamente Relevante para identifica{\c{c}}{\~{a}}o do Estado da Arte em Music Similarity.
Em Todo o levantamento as abordagens e algoritmos colocados conferem com a revis{\~{a}}o de literatura.
Excluido da tabela 3 pg 47 , muito provavel pois no caso do ... ele sempre retorna a mais relevante e os outros devido a n{\~{a}}o usarem dados simbolicos, n{\~{a}}o garantem o resultado sempre.
(Por isto que para o caso do ... a utiliza{\c{c}}{\~{a}}o de Reciprocal Rank n{\~{a}}o seja adequado).

Chaves: 
Music Similarity
State of The Art
Measure Evaluation},
author = {{Kuldeep Gurjar}, Yang-Sae Moon},
doi = {10.3745/JIPS.04.0054},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuldeep Gurjar - 2018 - A comparative analysis of music similarity measures in music information retrieval systems.pdf:pdf},
issn = {2092805X},
journal = {Journal of Information Processing Systems {\textperiodcentered} January 2018},
number = {January},
title = {{A comparative analysis of music similarity measures in music information retrieval systems}},
year = {2018}
}
@article{Al-ghawanmeh2011,
abstract = {The accuracy and reliability of automatic music transcription plays and important role in music information retrieval applications. This paper investigates a previously reported Automatic Music Transcription (AMT) system for the Arabian flute (Nay)with the aim of extending its features and improving its performance. Several critical design factors are considered in the new extension. A hybrid pitch detection method that utilizes both the autocorrelation and Fast Fourier Transform (FFT) is suggested and implemented in the improved AMT system. The signal power is also used to detect octave falls and to perform mapping from intensity to MIDI velocity. Experimental evaluation of the developed system has shown better transcription results when compared to original system.},
annote = {Apesar de nao falar sobre o assunto , mantive este artigo pois apresenta o processo de conversao das faixas do instrumento em notas simbolicas.
Chaves: 
Audio Processing
Hybrid},
author = {Al-ghawanmeh, F. and Jafar, I. and Al-taee, M and Al-ghawanmeh, M and Muhsin, Z.},
doi = {10.1109/SSD.2011.5993561},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-ghawanmeh et al. - 2011 - Development of improved automatic music transcription system for the arabian flute.pdf:pdf},
isbn = {978-1-4577-0413-0},
journal = {Eighth International Multi-Conference on Systems, Signals {\&} Devices},
pages = {1--6},
title = {{Development of improved automatic music transcription system for the arabian flute}},
url = {http://ieeexplore.ieee.org/document/5993561/},
year = {2011}
}
@article{Coviello2011,
abstract = {Many state-of-the-art systems for automatic music tagging model music based on bag-of-features representations which give little or no account of temporal dynamics, a key char- acteristic of the audio signal. We describe a novel approach to automatic music annotation and retrieval that captures temporal (e.g., rhythmical) aspects as well as timbral content. The proposed approach leverages a recently proposed song model that is based on a generative time series model of the musical content—the dynamic texture mixture (DTM) model—that treats fragments of audio as the output of a linear dynamical system. To model characteristic temporal dynamics and timbral content at the tag level, a novel, efficient, and hierarchical expectation–maximization (EM) algorithm for DTM (HEM-DTM) is used to summarize the common information shared by DTMs modeling individual songs associated with a tag. Experiments show learning the semantics of music benefits from modeling temporal dynamics. Index},
annote = {Artigo muito interessante a ser mantido apesar de n{\~{a}}o se relacionar diretamente ao projeto apresenta informa{\c{c}}{\~{o}}es detalhadas e algoritmos usados em cima de Chromagramas(imagens) e Filtros Convolucionais.
Chaves: 
Audio Processing
Convolution Kernels
Machine Learning
Music Similarity},
author = {Coviello, E. and Chan, A. B. and Lanckriet, G.},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coviello, Chan, Lanckriet - 2011 - Time series models for semantic music annotation.pdf:pdf},
journal = {IEEE Trans. on Audio, Speech and Language Processing},
number = {5},
pages = {1343--1359},
title = {{Time series models for semantic music annotation}},
volume = {19},
year = {2011}
}
@article{Downie1999,
abstract = {Taking our cue from those printed thematic catalogues that have reduced the amount of music information represented we developed, and then evaluated, a Music Inforrnation Retrieval (MIR) system based upon the intervals found within the melodies of a collection of 9354 folksongs. We believe that there is enough information contained within an interval-only representation of monophonic melodies that effective retrieval of music information has been achieved. We extended the thematic catalogue model by affording access to musical expressions found anywhere within a melody. To achieve this extension we fragmented to the melodies into length-n subsections called n-grams. The length of these n-grams and the degree to which we precisely represent the intervals are variables analyzed in this thesis.},
annote = {Chaves:
N-Grams},
author = {Downie, J. Stephen},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Downie - 1999 - Evaluating a Simple Approach to Music Information Retrieval Conceiving Melodic N-GRAMS as Text.pdf:pdf},
title = {{Evaluating a Simple Approach to Music Information Retrieval: Conceiving Melodic N-GRAMS as Text}},
year = {1999}
}
@article{Needleman1970,
abstract = {A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway. {\textcopyright} 1970.},
annote = {Artigo original do algoritmo de alinhamento Global.
Chaves: 
string-matching},
author = {Needleman, Saul B. and Wunsch, Christian D.},
doi = {10.1016/0022-2836(70)90057-4},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Needleman, Wunsch - 1970 - A general method applicable to the search for similarities in the amino acid sequence of two proteins.pdf:pdf},
isbn = {0022-2836},
issn = {00222836},
journal = {Journal of Molecular Biology},
number = {3},
pages = {443--453},
pmid = {5420325},
title = {{A general method applicable to the search for similarities in the amino acid sequence of two proteins}},
volume = {48},
year = {1970}
}
@article{Yu2008,
abstract = {This paper investigates the problem of retrieving karaoke music using query-by-singing techniques. Unlike regular CD music, where the stereo sound involves two audio channels that usually sound the same, karaoke music encompasses two distinct channels in each track: one is a mixture of the lead vocals and background accompaniment, and the other consists of accompaniment only. Although the two audio channels are distinct, the accompaniments in the two channels often resemble each other. We exploit this characteristic to: i) infer the background accompaniment for the lead vocals from the accompaniment-only channel, so that the main melody underlying the lead vocals can be extracted more effectively, and ii) detect phrase onsets based on the Bayesian information criterion (BIC) to predict the onset points of a song where a user's sung query may begin, so that the similarity between the melodies of the query and the song can be examined more efficiently. To further refine extraction of the main melody, we propose correcting potential errors in the estimated sung notes by exploiting a composition characteristic of popular songs whereby the sung notes within a verse or chorus section usually vary no more than two octaves. In addition, to facilitate an efficient and accurate search of a large music database, we employ multiple-pass dynamic time warping (DTW) combined with multiple-level data abstraction (MLDA) to compare the similarities of melodies. The results of experiments conducted on a karaoke database comprised of 1071 popular songs demonstrate the feasibility of query-by-singing retrieval for karaoke music.},
annote = {Artigo importante, realiza a quebra de notas sem dados simbolicos.
Me chamou a aten{\c{c}}{\~{a}}o estarem colocando o uso do DTW (Alinhamento Global) , mas colocando na formula MAX , caracteristico de alinhamento local.
Chaves
string-matching},
author = {Yu, Hung Ming and Tsai, Wei Ho and Wang, Hsin Min},
doi = {10.1109/TMM.2008.2007345},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Tsai, Wang - 2008 - A query-by-singing system for retrieving Karaoke music.pdf:pdf},
isbn = {1520-9210},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Bayesian information criterion,Dynamic time warping,Karaoke,Music information retrieval,Query-by-singing},
number = {8},
pages = {1626--1637},
title = {{A query-by-singing system for retrieving Karaoke music}},
volume = {10},
year = {2008}
}
@article{Packet2007,
abstract = {Many works in audio and image signal analysis are based on the use of "features" to represent characteristics of sounds or images. Features are used in various ways, for instance as inputs to classifiers to categorize automatically objects, e.g. for audio scene description. Most, if not all, approaches focus on the development of clever classifiers and on the various processes of feature selection, classifier algorithms and parameter tuning. Strangely, the features themselves are rarely justified. The predominant paradigm consists in selecting, by hand, "generic", well-known features from the literature and focusing on the rest of the chain. In this study we try to generalize the notion of feature to make the choice of features more systematic and less prone to hazardous, unjustified human choices. We introduce to this aim the notion of "analytical feature": features built only from the analysis of the problem at hand, using a heuristic function generation process. We show some experiments aiming at answering some general questions about analytical features.},
annote = {Artigo Extremamente importante para a lista de relevancia, trata da quest{\~{a}}o de n{\~{a}}o apenas selecionar features de musica, mas sim entender o qye est{\'{a}} por tr{\'{a}} delas.
Isto {\'{e}} importante j{\'{a}} que para Query-by-Playing regras musicais precisam ser processadas, nota por nota, onde varias delas n{\~{a}}o s{\~{a}}o providas por extratores de features symbolicas(JSymbolic)
Chaves:
Music Similarity
Features Extraction},
author = {Packet, Fran{\c{c}}ois and Roy, Pierre},
doi = {10.1109/CBMI.2007.385416},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Packet, Roy - 2007 - Exploring billions of audio features.pdf:pdf},
isbn = {1424410118},
journal = {CBMI'2007 - 2007 International Workshop on Content-Based Multimedia Indexing, Proceedings},
pages = {227--235},
title = {{Exploring billions of audio features}},
year = {2007}
}
@article{Lee2011,
abstract = {In this paper, we propose a music mood classification system that reflects a user's profile based on a belief that music mood perception is subjective and can vary depending on the user's profile such as age or gender. To this end, we first define a set of generic mood descriptors. Secondly, we make up several user profiles according to the age and gender. We then obtain musical items, for each group, to separately train the statistical models. Using the two different user models, we verify our hypothesis that the user profiles play an important role in mood perception by showing that both models achieve higher classification accuracy when the test data and the mood model are of the same kind. Applying our system to automatic play list generation, we also demonstrate that considering the difference between the user groups in mood perception has a significant effect in computing music similarity.},
annote = {statistical},
author = {Lee, Kyogu and Cho, Minsu},
doi = {10.1109/ICMLA.2011.96},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Cho - 2011 - Mood classfication from musical audio using user group-dependent models.pdf:pdf},
isbn = {9780769546070},
journal = {Proceedings - 10th International Conference on Machine Learning and Applications, ICMLA 2011},
pages = {130--135},
title = {{Mood classfication from musical audio using user group-dependent models}},
volume = {2},
year = {2011}
}
@article{Shen2011,
author = {Shen, Hung Che and Lee, Chung Nan},
doi = {10.1007/s11042-010-0510-6},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen, Lee - 2011 - An interactive Whistle-to-Music composing system based on transcription, variation and chords generation.pdf:pdf},
issn = {13807501},
journal = {Multimedia Tools and Applications},
keywords = {Lead sheet notation,Melodic variation,Music templates,Transcription templates,Whistle-to-MIDI},
number = {1},
pages = {253--269},
title = {{An interactive Whistle-to-Music composing system based on transcription, variation and chords generation}},
volume = {53},
year = {2011}
}
@article{Magnusson2014,
abstract = {Fostered by the introduction of the Music Information Retrieval Evaluation Exchange (MIREX) competition, the number of systems that calculate symbolic melodic similarity has recently increased considerably. To understand the state of the art, we provide a comparative analysis of existing algorithms. The analysis is based on eight criteria that help to characterize the systems, highlighting strengths and weaknesses. We also propose a taxonomy that classifies algorithms based on their approach. Both taxonomy and criteria are fruitfully exploited to provide input for new, forthcoming research in the area.},
annote = {Verificar de Novo , pois esta gerando duplicidade no Mendeley em um arquivo i8mportante de State of the Art.

Chaves: 
Music Similarity
State of the Art},
author = {{Valerio Velardo, Mauro Vallati}, Steven Jan},
doi = {10.1162/COMJ},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Magnusson - 2014 - Herding Cats Observing Live Coding in the Wild(4).pdf:pdf},
isbn = {8187672641},
issn = {1531-5169},
journal = {Computer Music Journal},
number = {1},
pages = {8--16},
title = {{Symbolic Melodic Similarity: State of the Art and Future Challenges}},
volume = {38},
year = {2016}
}
@article{Heryanto2011,
annote = {Artigo Extremamente valioso!
Mostra o estado da arte ate 2010 e possui referencias importantes a serem incluidas no Snow Ball.
tem alguns comentarios importantes de trabalhos focados em encontrar as melhores features para similaridade e ja nesta data come{\c{c}}ou a se fazer a subdivisao de algoritmos por finalidade.
Chaves: 
Music Similarity
State of The Art},
author = {Heryanto, Hery and Akbar, Saiful and Sitohang, Bernhard},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Heryanto, Akbar, Sitohang - 2011 - Direct Acccess in Content-Based Audio Information Retrieval - A State of the Art and Challenges.pdf:pdf},
isbn = {9781457707513},
journal = {Proceedings of the International Conference on Electrical Engineering and Informatics, Bandung, Indonesia, July 17-19.},
keywords = {and,audio indexing,content based retrieval,extraction,feature,multimedia database,semantic search},
number = {July},
title = {{Direct Acccess in Content-Based Audio Information Retrieval - A State of the Art and Challenges}},
url = {https://docs.google.com/file/d/0B3N-C9xfG{\_}CPWVdNZEpTUVBid1k/edit},
year = {2011}
}
@article{Hu2003,
abstract = {We describe a method that aligns polyphonic audio recordings of music to symbolic score information in standard MIDI files without the difficult process of polyphonic transcription. By using this method, we can search through a MIDI database to find the MIDI file corresponding to a polyphonic audio recording.},
annote = {Artigo Interessant{\'{i}}ssimo!
Basicamente o objetivo aqui {\'{e}} encontrar similaridade entre um arquivo de {\'{a}}udio e seu correspondente em MIDI.
Para isto {\'{e}} criado um Cromagrama(imagem) das frequencias e pitchs e usado o DTW para verificar a similaridade.
Chaves: 
Music Similarity
DTW
Cromagram
string-matching},
author = {Hu, Ning and Dannenberg, R.B. and Tzanetakis, George},
doi = {10.1109/ASPAA.2003.1285862},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Dannenberg, Tzanetakis - 2003 - Polyphonic Audio Matching and Alignment for Music Retrieval.pdf:pdf},
isbn = {0780378504},
journal = {2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings.},
pages = {185--188},
title = {{Polyphonic Audio Matching and Alignment for Music Retrieval}},
url = {https://www.cs.cmu.edu/{~}rbd/papers/waspaa03alignment.pdf},
year = {2003}
}
@article{McNab1996,
abstract = {Music is traditionally retrieved by title, composer or subject classification. It is possible, with current technology, to retrieve music from a database on the basis of a few notes sung or hummed into a microphone. This paper describes the implementation of such a system, and discusses several issues pertaining to music retrieval. We first describe an interface that transcribes acoustic input into standard music notation. We then analyze string matching requirements for ranked retrieval of music and present the results of an experiment which tests how accurately people sing well known melodies. The performance of several string matching criteria are analyzed using two folk song databases. Finally, we describe a prototype system which has been developed for retrieval of tunes from.},
annote = {Artigo de 1996 imprescindivel de estar na lista de referencias. Fala dos maiores problemas na epoca sobre string matching.
Este foi o unico artigo que vi citar coisas importantes e que serao tratadas no SIMILA, como oitavas , notas diatonicas e etc...
Acredito que isto ocorra pois a grande maioria dos artigos extraidos n{\~{a}}o apresentaram como alvo mapear regras musicais para o calculo da similaridade.
Chaves: 
string-matching},
author = {McNab, Rodger J and Smith, Lloyd a and Witten, Ian H and Henderson, Clare L and Cunningham, Sally Jo},
doi = {10.1.1.30.364},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McNab et al. - 1996 - Towards the Digital Music Library Tune Retrieval from Acoustic Input.pdf:pdf},
isbn = {0897918304},
journal = {Proceedings of Digital Libraries},
keywords = {acoustic,interfaces,melody recall,music retrieval,relevance ranking},
number = {1978},
pages = {11--18},
title = {{Towards the Digital Music Library: Tune Retrieval from Acoustic Input}},
url = {http://portal.acm.org/citation.cfm?id=226934},
year = {1996}
}
@article{Lambrou1998,
abstract = {This paper presents a study on musical signal classification, using wavelet transform analysis in conjunction with statistical pattern recognition techniques. A comparative evaluation between different wavelet analysis architectures in terms of their classification ability, as well as between different classifiers is carried out. We seek to establish which statistical measures clearly distinguish between the three different musical styles of rock, piano, and jazz. Our preliminary results suggest that the features collected by the adaptive splitting wavelet transform technique performed better compared to the other wavelet based techniques, achieving an overall classification accuracy of 91.67{\%}, using either the minimum distance classifier or the least squares minimum distance classifier. Such a system can play a useful part in multimedia applications which require content based search, classification, and retrieval of audio signals, as defined in MPEG-7},
annote = {Palavras Chave:
statistical},
author = {Lambrou, T and Kudumakis, P and Speller, R and Sandler, M and Linney, a},
doi = {10.1109/ICASSP.1998.679665},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lambrou et al. - 1998 - Classification of audio signals using statistical features on time and wavelet transform domains.pdf:pdf},
isbn = {0780344286},
journal = {{\ldots} , Speech and Signal {\ldots}},
number = {Mdc},
pages = {3621--3624},
title = {{Classification of audio signals using statistical features on time and wavelet transform domains}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=679665},
year = {1998}
}
@article{SebastianStober2011,
abstract = {Some popular algorithms used in Music Information Retrieval (MIR) such as Self-Organizing Maps (SOMs) require the ob- jects they process to be represented as vectors, i.e. elements of a vector space. This is a rather severe restriction and if the data does not adhere to it, some means of vectorization is required. As a common practice, the full distance matrix is computed and each row of the matrix interpreted as an artifi- cial feature vector. This paper empirically investigates the im- pact of this transformation. Further, an alternative approach for vectorization based on Multidimensional Scaling is pro- posed that is able to better preserve the actual distance rela- tions of the objects which is essential for obtaining a good retrieval performance.},
annote = {Artigo Extremamente importante de estudo durante o Mestrado, foca no estudo de vetoriza{\c{c}}{\~{a}}o de dados musicais no estudo de MIR.
O Foco central da proposta do mestrado {\'{e}} justamente mixar dados espaciais com simbolicos para o funcionamento do algoritmo , que sofreu atualmente uma altera{\c{c}}{\~{a}}o de uma estrutura musical de 8 features para processamento de regras musicais dentro do vetor de features de nota.

Chaves: 
Audio Processing
Features Extraction
Music Datasets
Music Similarity
Geometric Space},
author = {{Sebastian Stober}, Andreas N¨urnberger},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sebastian Stober - 2011 - Analysing the Impact of Data Vectorization on Distance Relations.pdf:pdf},
isbn = {9781612843506},
journal = {IEEE},
pages = {1--6},
title = {{Analysing the Impact of Data Vectorization on Distance Relations}},
year = {2011}
}
@article{Aucouturier2005,
abstract = {—Electronic Music Distribution is in need of robust and automatically extracted music descriptors. An important attribute of a piece of polyphonic music is what is commonly referred to as “the way it sounds”. While there has been a large quantity of re- search done to model the timbre of individual instruments, little work has been done to analyze “real world” timbre mixtures such as the ones found in popular music. In this paper, we present our re- search about such “polyphonic timbres”. We describe an effective way to model the textures found in a given music signal, and show that such timbre models provide new solutions to many issues tra- ditionally encountered in music signal processing and music infor- mation retrieval. Notably, we describe their applications for music similarity, segmentation and pattern induction.},
annote = {Artigo importante para ser mantido pois apesar de falar sobre modelagem de timbres, cita um framework chamado Cuidado que busca similaridade nos timbres(Query By Timbre)
Chaves: 
Music Similarity
Audio Processing},
author = {Aucouturier, Jean-julien and Pachet, Fran{\c{c}}ois and Sandler, Mark},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aucouturier, Pachet, Sandler - 2005 - The way it Sounds timbre models for analysis and retrieval of music signals.pdf:pdf},
journal = {IEEE Transactions on Multimedia},
number = {6},
pages = {1--8},
title = {{"The way it Sounds": timbre models for analysis and retrieval of music signals}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.3853{\&}rep=rep1{\&}type=pdf},
volume = {7},
year = {2005}
}
@article{Bohm2017,
abstract = {The quality of the singing voice is an important aspect of subjective, aesthetic perception of music. In this contribution, we propose a method to automatically assess perceived singing quality. We classify monophonic vocal recordings without accompaniment into one of three classes of singing quality. Unprocessed private and non-commercial recordings from a social media website are utilised. In addition to the user ratings given on the website, we let both subjects with and without a musical background annotate the samples. Building on musicological foundations, we define and extract acoustic parameters describing the quality of the sound, musical expression and intonation of the singing. Besides features which are already established in the field of Music Information Retrieval, such as loudness and mel-frequency cepstral coefficients, we propose and employ new types of features which are specific to intonation. For automatic classification by supervised machine learning methods, models predicting the subjective ratings and the user ratings on the social media website are learnt. We perform an exhaustive evaluation of both different classifiers and combinations of features. We show that the performance of automatic classification is close to that of human evaluators. Utilising support vector machines, an accuracy of classification of 55.4 {\%}, based on the subjective ratings, and of 84.7 {\%}, based on the user ratings of the social media website, are achieved. {\textcopyright} 2017 IEEE.},
annote = {Artigo atual e puramente focado em Machine Learning, foca na identifica{\c{c}}{\~{a}}o de se um cantor {\'{e}} profissional ou n{\~{a}}o.
Artigo valioso para montar base de pesquisa futura, n{\~{a}}o possui rela{\c{c}}{\~{a}}o com o mestrado, mas da imforma{\c{c}}{\~{o}}es interessantes de maneira geral.
Chaves: 
Music Datasets
Machine Learning
Audio Processing},
author = {Bohm, Johanna and Eyben, Florian and Schmitt, Maximilian and Kosch, Harald and Schuller, Bjorn},
doi = {10.1109/IJCNN.2017.7966037},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bohm et al. - 2017 - Seeking the SuperStar Automatic assessment of perceived singing quality.pdf:pdf},
isbn = {9781509061815},
journal = {Proceedings of the International Joint Conference on Neural Networks},
pages = {1560--1569},
title = {{Seeking the SuperStar: Automatic assessment of perceived singing quality}},
volume = {2017-May},
year = {2017}
}
@article{MarcelMongeau1990,
abstract = {Concepts from the theory of sequence comparison are adapted to measure the overall similarity or dissimilarity between two musical scores. A key element is the notion of consolidation and fragmentation, different both from the de- letions and insertions familiar in sequence comparison, and from the compressions and expansions of time warping in automatic speech recognition. The measure of comparison is defined so as to detect similarities in melodic line despite gross differences in key, mode or tempo. A dynamic pro- gramming algorithm is presented for calculating the measure, and is programmed and applied to a set of variations on a theme by Mozart. Cluster analysis and spatial representation of the results confirm subjective impressions of the patterns of similarities among the variations. A generalization of the algorithm is presented for detecting locally similar portions in two scores, and is then applied.},
annote = {Chaves:
string-matching},
author = {{Marcel Mongeau}, David Sankoff},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Marcel Mongeau - 1990 - Comparison of Musical Sequences.pdf:pdf},
journal = {Computers and the Humanities},
keywords = {dynamic programming,melodic line,musical pattern recognition,sequence comparison},
pages = {161--175},
title = {{Comparison of Musical Sequences}},
volume = {24},
year = {1990}
}
@article{Langlois2009,
abstract = {Automatic music genre classification has received a lot of attention from the Music Information Retrieval (MIR) community in the past years. Systems capable of discriminating music genres are essential for managing music databases. This paper presents a method for music genre classification based solely on the audio contents of the signal. The method relies on a language modeling approach and takes in account the temporal information of the music signals for genre classification. First, the music data is transformed into a sequence of symbols, and a model is derived for each genre by estimating n-grams from the training data. As a term o comparison, HMMs models for each musical genre were also implemented. Tests on different audio sets show that the proposed approach performs very well, and outperforms HMMs based methods.},
annote = {Chaves:
N-Grams},
author = {{Thibault Langlois}, Gon{\c{c}}alo Marques},
doi = {10.1109/MMEDIA.2009.42},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Thibault Langlois - 2009 - Automatic Music Genre Classification Using a Hierarchical Clustering and a Language Model Approach.pdf:pdf},
isbn = {978-0-7695-3693-4},
journal = {2009 First International Conference on Advances in Multimedia},
pages = {188--193},
title = {{Automatic Music Genre Classification Using a Hierarchical Clustering and a Language Model Approach}},
url = {http://ieeexplore.ieee.org/document/5206888/},
year = {2009}
}
@article{Ferraro2007,
annote = {Neste artigo {\'{e}} proposto o uso de Average Dynamic Recall (ADR) para avalia{\c{c}}{\~{a}}o dos resultados do Edit-Distance.
Chaves: 
Measure Evaluation
string-matching},
author = {Ferraro, Pascal and Hanna, Pierre},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferraro, Hanna - 2007 - Optimizations of local edition for evaluating similarity between monophonic musical sequences.pdf:pdf},
journal = {Large Scale Semantic Access to Content (Text, Image, Video, and Sound)},
number = {1970},
pages = {64--69},
title = {{Optimizations of local edition for evaluating similarity between monophonic musical sequences}},
year = {2007}
}
@article{Li2016,
abstract = {One challenge in score following for piano music is the sustained effect, i.e., the waveform of a note lasts longer than what is notated in the score. This can be caused by expressive performing styles such as the legato articulation and the usage of the sustain and the sostenuto pedals and can also be caused by the reverberation in the recording environment. This effect creates nonnotated overlappings between sustained notes and latter notes in the audio. It decreases the audio-score alignment accuracy and robustness of score following systems and makes them be prone to delay errors, i.e., aligning audio to a score position that is earlier than the correct position. In this paper, we propose to modify the feature representation of the audio to attenuate the sustained effect. We show that this idea can be applied to both the chromagram and the spectral-peak representations, which are commonly used in score following systems. Experiments on the MAPS dataset show that the proposed method significantly improves the alignment accuracy and robustness of score following systems for piano performances, in both anechoic and highly reverberant environments.},
annote = {Sem rela{\c{c}}{\~{a}}o com o Mestrado , foca em processamento de Audio que pode ser importante para o futuro, pois aborda acompanhamento de score de musica ao pressionar o pedal de sustain do piano.
Chaves: 
Audio Processing
Audio Match},
author = {Li, Bochen and Duan, Zhiyao},
doi = {10.1109/TASLP.2016.2611938},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Duan - 2016 - An Approach to Score Following for Piano Performances with the Sustained Effect.pdf:pdf},
issn = {23299290},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
keywords = {Audio-score alignment,reverberation,score following,sustain pedal},
number = {12},
pages = {2425--2438},
title = {{An Approach to Score Following for Piano Performances with the Sustained Effect}},
volume = {24},
year = {2016}
}
@article{A.N.2009,
abstract = {With the increasing popularity of music, there is an intensive need for an efficient and natural way of querying an audio database in order to retrieve the desired songs. This paper presents a system that accepts user input, usually a tune hummed or sung by the user, which accounts for the most natural way of retrieval. A modified form of Dynamic Time Warping technique is used as a similarity metric in order to suit for various humming/singing habits of the user. This technique is employed to compare a given user input to a number of songs stored in the database and performs an exhaustive search to return results as a list of matching songs.},
annote = {Artigo interessante, focado em apenas mostrar o que foi usado na implementa{\c{c}}{\~{a}}o de similaridade, limpo direto e contem todas as partes de uma busca.
Palavras Chave:
Music Similarity
DTW},
author = {A.N., Myna and V., Chaitra and K.S., Smitha},
doi = {10.1109/CSIE.2009.792},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/A.N., V., K.S. - 2009 - Melody Information Retrieval System Using Dynamic Time Warping.pdf:pdf},
isbn = {978-0-7695-3507-4},
journal = {2009 WRI World Congress on Computer Science and Information Engineering},
keywords = {dynamic time warping,melody,midi,monophonic,musical instrument digital interface,polyphonic},
pages = {266--270},
title = {{Melody Information Retrieval System Using Dynamic Time Warping}},
url = {http://ieeexplore.ieee.org/document/5170538/},
year = {2009}
}
@article{Krishnamoorthy2010,
abstract = {Query by humming (QBH) is a method of searching for a songs in a multimedia database system that contains the melody descriptions of songs. The database of songs can be searched by hummed queries. The user hums a melody into a microphone that is connected to any handheld device and the QBH system searches the database of songs which are similar to the input query and returns the result to the user as a list of songs that match. The main objective of this paper is to propose a QBH system for embedded devices like mobile phones, MP3 players etc., To achieve the same the algorithms for the extraction of feature and their symbolic representation, from the query signal and the database are described. A novel string matching technique to compare the feature representation of query and database of songs are also described. Our retrieval database is built on 100 MIDI files and evaluated using 440 hummed samples from 40 people with different musical backgrounds. A retrieval accuracy of 83{\%} is demonstrated for humming samples from musically untrained subjects.},
annote = {Artigo importante apesar de focar em machine learning, fala sobre a utiliza{\c{c}}{\~{a}}o de similaridade usando o Edit-Distance e a forma que esta avaliando os resultados.
Chaves: 
Music Similarity
Machine Learning
Edit-Distance
Measure Evaluation},
author = {Krishnamoorthy, P. and Bhatt, Rajen and Srinivas, A. and Kumar, Sarvesh},
doi = {10.1109/INDCON.2010.5712695},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krishnamoorthy et al. - 2010 - Query by humming system for embedded platforms.pdf:pdf},
isbn = {9781424490745},
journal = {Proceedings of the 2010 Annual IEEE India Conference: Green Energy, Computing and Communication, INDICON 2010},
keywords = {Music information retrieval and string edit distan,Query by humming},
title = {{Query by humming system for embedded platforms}},
year = {2010}
}
@article{Unal2007,
abstract = {AbstractIn this article, we propose a solution to the problem of query by example for polyphonic music audio.We first present a generic mid-level representation for audio queries. Unlike previous efforts in the literature, the proposed representation is not dependent on the different spectral characteristics of different musical instruments and the accurate location of note onsets and offsets. This is achieved by first mapping the short term frequency spectrum of consecutive audio frames to the musical space (The Spiral Array) and defining a tonal identity with respect to center of effect that is generated by the spectral weights of the musical notes. We then use the resulting single dimensional text representations of the audio to create n-gram statistical sequence models to track the tonal characteristics and the behavior of the pieces. After performing appropriate smoothing, we build a collection of melodic n-gram models for testing. Using perplexity-based scoring, we test the likelihood of a sequence of lexical chords (an audio query) given each model in the database collection. Initial results show that, some variations of the input piece appears in the top 5 results 81{\%} of the time for whole melody inputs within a 500 polyphonic melody database. We also tested the retrieval engine for small audio clips. Using 25s segments, variations of the input piece are among the top 5 results 75{\%} of the time.},
annote = {Palavras Chave:
statistical},
author = {Unal, Erdem and Georgiou, Panayiotis G. and Narayanan, Shrikanth S. and Chew, Elaine},
doi = {10.1109/MMSP.2007.4412902},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unal et al. - 2007 - Statistical modeling and retrieval of polyphonic music.pdf:pdf},
isbn = {1424412749},
journal = {2007 IEEE 9Th International Workshop on Multimedia Signal Processing, MMSP 2007 - Proceedings},
pages = {405--409},
title = {{Statistical modeling and retrieval of polyphonic music}},
year = {2007}
}
@article{Adams2006,
abstract = { Much research in music information retrieval has focused on query-by-humming systems, which search melodic databases using sung queries. The database retrieval aspect of such systems has received considerable attention, but query processing and the melodic representation have not been examined as carefully. Common methods for query processing are based on musical intuition and historical momentum rather than specific performance criteria; existing systems often employ rudimentary note segmentation or coarse quantization of note estimates. In this work, we examine several alternative query processing methods as well as quantized melodic representations. One common difficulty with designing query-by-humming systems is the coupling between system components. We address this issue by measuring the performance of the query processing system both in isolation and coupled with a retrieval system. We first measure the segmentation performance of several note estimators. We then compute the retrieval accuracy of an experimental query-by-humming system that uses the various note estimators along with varying degrees of pitch and duration quantization. The results show that more advanced query processing can improve both segmentation performance and retrieval performance, although the best segmentation performance does not necessarily yield the best retrieval performance. Further, coarsely quantizing the melodic representation generally degrades retrieval accuracy.},
annote = {Artigo important{\'{i}}ssivo de estar na lista de artigos altamente relevantes. Fala da segmenta{\c{c}}{\~{a}}o de audio em notas por pitch e tempo(Como representado pelos arquivos MIDI).
Este artigo tambem expoe a importancia do Convolution Kernel implementado para o desenvolvimento do QBPLab j{\'{a}} que o mesmo pode ser aplicado como um filtro de Audio.

Palavras Chave:
Audio Processing
Music Similarity
Segmentation Algoritms
Convolution Kernels},
author = {Adams, Norman H. and Bartsch, Mark A. and Wakefield, Gregory H.},
doi = {10.1109/TSA.2005.854088},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Adams, Bartsch, Wakefield - 2006 - Note segmentation and quantization for music information retrieval.pdf:pdf},
isbn = {1558-7916},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Music information retrieval,Pitch,Pitch quantization,Query-by-example,Segmentation},
number = {1},
pages = {131--141},
title = {{Note segmentation and quantization for music information retrieval}},
volume = {14},
year = {2006}
}
@article{Bayle2017,
abstract = {We introduce Kara1k, a new musical dataset com- posed of 2,000 analyzed songs thanks to a partnership with a karaoke company. The dataset is divided into 1,000 cover songs provided by Recisio Karafun application1, and the corresponding 1,000 songs by the original artists. Kara1k is mainly dedicated toward cover song identification and singing voice analysis. For both tasks, it offers novel approaches, as each cover song is a studio-recorded song with the same arrangement as the original recording, but with different singers and musicians. Essentia, harmony-analyser, Marsyas, Vamp plugins and YAAFE have been used to extract audio features for each track in Kara1k. We provide metadata such as the title, genre, original artist, year, International Standard Recording Code and the ground truths for the singer's gender, backing vocals, duets, and lyrics' language. Additionally, we provide the instrumental track and the pure singing voice track for each cover song. We showcase two use-case experiments for Kara1k. In the cover song identification task using the Dynamic Time Warping method, we provide a comparison of traditional and new features: chroma and MFCC features, chords and keys, and chroma and chord distances. We obtain 84-89{\%} identification accuracy for three of the features, which justifies our focus on karaoke songs. In the supporting experiment on singer gender classification, we evaluate the difference in the performance in two conditions – a pure singing voice and the singing voice mixed with the background music. The Kara1k dataset is freely available under the KaraMIR project website2. I.},
annote = {Artigo interessante para ter na lista, aborda exclusivamente um dataset para identifica{\c{c}}{\~{a}}o de musicas Cover.
Artigo atual
Palavras Chave:
Music Similarity
Music Datasets},
author = {Bayle, Yann and Marsik, Ladislav and Rusek, Martin and Robine, Matthias and Hanna, Pierre and Slaninova, Katerina and Martinovic, Jan and Pokorny, Jaroslav},
doi = {10.1109/ISM.2017.32},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bayle et al. - 2017 - Kara1k A Karaoke Dataset for Cover Song Identification and Singing Voice Analysis.pdf:pdf},
isbn = {978-1-5386-2937-6},
journal = {2017 IEEE International Symposium on Multimedia (ISM)},
pages = {177--184},
title = {{Kara1k: A Karaoke Dataset for Cover Song Identification and Singing Voice Analysis}},
url = {http://ieeexplore.ieee.org/document/8241597/},
year = {2017}
}
@article{MattMcVicarRaulSantos-Rodriguez2014,
abstract = {In this overview article, we review research on the task of Automatic Chord Estimation (ACE). The major contribu- tions from the last 14 years of research are summarized, with de- tailed discussions of the following topics: feature extraction, mod- eling strategies, model training and datasets, and evaluation strate- gies. Results from the annual benchmarking evaluation Music In- formation Retrieval Evaluation eXchange (MIREX) are also dis- cussed as well as developments in software implementations and the impact of ACE within MIR. We conclude with possible direc- tions for future research.},
author = {{Matt McVicar, Ra{\'{u}}l Santos-Rodr{\'{i}}guez}, Yizhao Ni and Bie, Tijl De},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Matt McVicar, Ra{\'{u}}l Santos-Rodr{\'{i}}guez, Bie - 2014 - Automatic Chord Estimation from Audio A Review of the State of the Art.pdf:pdf},
journal = {IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING},
keywords = {Music information retrieval,expert systems,knowledge based systems,machine learning,supervised learning},
number = {2},
pages = {1--20},
title = {{Automatic Chord Estimation from Audio : A Review of the State of the Art}},
volume = {22},
year = {2014}
}
@article{MarvinWest1988,
abstract = {This dissertation proposes the thesis that abstract theories of pitch- and set-class structure do not reflect listeners' aural perception of sounding music as effectively as theories modelling the articulation of these underlying structures on the musical surface. This position is supported by a review of pertinent music-theoretical and music-psychological research. Based upon the data collected by various music-psychologists, published elsewhere but compared and critiqued here, this study concludes that listeners generally use figural cues drawn from musical context for example, melodic shapes, changes of direction, relative durationnal patterns, and so on to retain and recognize musical ideas in short-term memory. These figural cues may be represented in precise notation and compared with one another by application and generalization of Robert Morris's contour theories. Morris's comparison matrix and contour equivalence relations are introduced here, followed by this author's generalization of the thwory to duration space and development of similarity relations for melodic contours of relative pitch height and rhythmic contours of relative suration successions. The similarity relations for musical contours build upon previous wort of Dabid Lewin, Robert Morris, and John Rahn. While the efficacy of these theories for modelling perceivable patterns in musical contexts cannot be proven without further psychological testing, their applicability to musical analysis is demonstrated. Analyses drawn form the music of Bartok, Webern, Berg, and Var{\`{e}}se illustrate ways in which melodic and rhythmic contour relationships may be used to shape a formal scheme to differentiate melody from accompaniment, to associate musical ideas that belong to different set classes, and to create unity throuth varied repetition. The concluding chapter explores avenues for future work. A section on music-psychological experimentation offers a critical overview of research in this area and proposes ideas for future experimentation. Second, the implications of music-psychological research for the pedagogy of non-tonal music theory are considered and a model curriculum for non-tonal music theory proposed. The dissertation concludes by proposing a number of ways in which contour theory might be generalized to other domains and illustrates the application of one such generalization to the analysis of chord spacing in a piano work of Luigi Dallapiccola.},
author = {Marvin, Elizabeth West},
file = {:C$\backslash$:/Wolff/QBPLab/bin/docs/Artigos/Melodic Contour/Marvin diss.pdf:pdf},
title = {{A generalized theory of musical contour: its application to melodic and rhythmic analysis of non-tonal music and its perceptual and pedagogical implications}},
url = {http://www.mendeley.com/research/a-generalized-theory-of-musical-contour-its-application-to-melodic-and-rhythmic-analysis-of-nontonal-music-and-its-perceptual-and-pedagogical-implications/},
year = {1988}
}
@article{Chuan2013,
abstract = {This paper presents a multimodal approach to style identification in pop/rock music. Considering the intuitive feelings of similarity from the listener's perspective, this study focuses on features that are computed using similarity metrics for melodies, harmonies, and audio signals for style identification. Support vector machine is used as a binary classifier to determine if two songs are created by the same artist given their similarity distances in the three aspects. Experiments are conducted using songs of four well-known pop/rock bands from 6 albums. The preliminary result shows that the approach achieves the best result in correct rate of 85{\%} using only seven similarity metrics. {\textcopyright} 2013 IEEE.},
annote = {Sinceramente...este nao mostra no texto tudo que foi definido no abstract e o autor deixa em aberto muitas coisas(Porque nao deu nome para cada n-gram???).
mantive devido a apresentar a tecnica ngrams e relativo a importancia deles na extracao de features e consecutiva gera{\c{c}}ao de dados para Machine learning, porem fiquei ate em duvida se este autor realmente executou este trabalho, ou apenas citou referencias de outros para corroborar um artigo sem detalhamentos...
T{\~{a}}o confuso que ate o autor diz que executou treinamentos com diversos dados extraidos de 3 ngrams, mas detalha que cada um possui diversas informacoes e apenas diz que usou SVM no abstract..nao diz nem quantas e quais features usou...apenas diagramas utilizando as 3....mas...se cada n-gram prove diversas caracteristicas...ficou em aberto qual foi o criterio de "mixagem" destes valores...e etc...
Nos datasets diz que usou faixas musicais, mas as features sao extraidas a partir de dados simbolicos(Ele converteu isto??) Como???
Classificador Binario para classificar estilo???Que porra e esta? N{\~{a}}o sao varias classes??? , uma para cada musico??? muito esquisito...59 musicas s{\'{o}}!!! ixi...fiquei ate com medo de manter na lista de referencias....affff...

Chaves:
N-Grams},
author = {Chuan, Ching Hua},
doi = {10.1109/ICMLA.2013.143},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chuan - 2013 - A multimodal approach to song-level style identification in poprock using similarity metrics.pdf:pdf},
isbn = {978-0-7695-5144-9},
journal = {2013 12th International Conference on Machine Learning and Applications},
keywords = {acoustic similarity is,durations,gaussian mixture models,mahalanobis distance between the,melodic contour,music,n-grams,produced by computing the,similarity,style,weighted by the patterns},
pages = {321--324},
title = {{A multimodal approach to song-level style identification in pop/rock using similarity metrics}},
url = {http://ieeexplore.ieee.org/document/6786128/},
volume = {2},
year = {2013}
}
@article{Kroher2015,
abstract = {This paper presents a method for the discovery of repeated vocal patterns directly from music recordings. At a first stage, a voice detection algorithm provides a rough segmentation of the recording to vocal parts, based on which an estimate of the average pattern duration is computed. Then, a pattern detector which employs a sequence alignment algorithm is used to yield a ranking of pairs of matches of the detected voiced segments. At a last stage, a clustering algorithm produces the final repeated patterns. Our method was evaluated in the context of flamenco music for which symbolic metadata are very hard to produce, yielding very promising results.},
annote = {Artigo a ser lido novamente.
Achei uma sacanagem n{\~{a}}o terem reconhecido o algoritmo Como base do reconhecimento da similaridade.
Neste artigo fizeram o mesmo que o BIRITS porem ao inves de criar uma matriz de pesos para alterar os GAPS , foi criado um Cromagrama das frequencias...
O artigo cita estimativas de performance definidas pela MIREX...revisitar o artigo para estud{\'{a}}-las!!!

Chaves: 
Measure Evaluation
geometric-representation},
author = {Kroher, Nadine and Pikrakis, Aggelos and Moreno, Jesus and Diaz-Banez, Jose Miguel},
doi = {10.1109/EUSIPCO.2015.7362341},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kroher et al. - 2015 - Discovery of repeated vocal patterns in polyphonic audio A case study on flamenco music.pdf:pdf},
isbn = {9780992862633},
journal = {2015 23rd European Signal Processing Conference, EUSIPCO 2015},
keywords = {Pattern discovery,flamenco music},
pages = {41--45},
title = {{Discovery of repeated vocal patterns in polyphonic audio: A case study on flamenco music}},
year = {2015}
}
@article{Bryan2013,
annote = {Artigo Muito Interessante para um possivel estudo futuro usando similaridade para track sepparation.
Chaves: 
Audio Processing},
author = {Bryan, Nicholas J. and Mysore, Gautham J. and Wang, G.},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bryan, Mysore, Wang - 2013 - Source Separation of Polyphonic Music with Interactive User-Feedback on a Piano Roll Display.pdf:pdf},
journal = {International Society for Music Information Retrieval Conference (ISMIR)},
pages = {119--124},
title = {{Source Separation of Polyphonic Music with Interactive User-Feedback on a Piano Roll Display}},
year = {2013}
}
@article{Ganguli2017,
abstract = {{\textcopyright} 2017 IEEE. In Hindustani classical music, melodic phrases are identified not only by the stable notes at precise pitch intervals but also by the shapes of the continuous transient pitch segments connecting these. Time-series matching via subsequence dynamic time warping (DTW) facilitates the equal contribution of stable notes and transients to the computation of similarity between pitch contour segments corresponding to melodic phrases. In the interest of reducing computational complexity it is advantageous to replace time-series DTW with low-dimensional string matching provided a principled approach to the time-series to symbolic string conversion is available. While the stable notes easily lend themselves to quantization, we address the compact representation of the transient pitch segments in this work. We analyze the design considerations at each stage: pitch curve fitting, normalization (with respect to pitch interval and duration), shape dictionary generation, inter-symbol proximity measure and string matching cost functions. A combination of domain knowledgeand data-driven optimization on a database of raga music is exploited to design the melodic representation of a raga phrase that enables a performance comparable to the time series based matching in an audio search by query task at significantly lower computational cost.},
annote = {Cita algumas informa{\c{c}}{\~{o}}es importantes sobre o calculo de penalidades no algoritmo Smith Waterman WS.

aRTIGO EXCELENTE TAMB{\'{E}}M COMO REFERENCIA A UTILIZA{\c{C}}{\~{A}}O DE SEMI-TONS PARA A PARAMETRIZA{\c{C}}{\~{A}}O SW},
author = {Ganguli, Kaustuv Kanti and Lele, Ashwin and Pinjani, Saurabh and Rao, Preeti and Srinivasamurthy, Ajay and Gulati, Sankalp},
doi = {10.1109/NCC.2017.8077055},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ganguli et al. - 2017 - Melodic shape stylization for robust and efficient motif detection in hindustani vocal music.pdf:pdf},
isbn = {9781509053568},
journal = {2017 23rd National Conference on Communications, NCC 2017},
title = {{Melodic shape stylization for robust and efficient motif detection in hindustani vocal music}},
year = {2017}
}
@article{Raden-2018-teaching,
abstract = {The investigation of RNA-based regulation of cellular processes is becoming an increasingly important part of biological or medical research. For the analysis of this type of data, RNA-related prediction tools integrated into of many pipelines and workflows. In order to correctly apply and tune these programs, the user has to have a precise understanding of their limitations and concepts. Within this manuscript, we provide the mathematical foundations and extract the algorithmic ideas that are core to state-of-the-art RNA structure and RNA-RNA interaction prediction algorithms. To allow the reader to change and adapt the algorithms or to play with different inputs, we provide an open-source web interface to JavaScript implementations and visualizations of each algorithm. The conceptual, teaching-focused presentation enables a high-level survey of the approaches while providing sufficient details for understanding important concepts. This is boosted by the simple generation and study of examples using the web interface available under http://rna.informatik.uni-freiburg.de/Teaching/. In combination, we provide a valuable resource for teaching, learning and understanding the discussed prediction tools and thus enable a more informed analysis of RNA-related effects.},
annote = {Gap Penalty},
author = {Raden, Martin and Mohamed, Mostafa M and Ali, Syed M and Backofen, Rolf},
doi = {10.1371/journal.pcbi.1006341},
file = {:C$\backslash$:/Wolff/Referencias QBP/Raden-2018-teaching.pdf:pdf},
issn = {1553-7358},
journal = {PLOS Comput. Biol},
number = {8},
pages = {e1006341},
title = {{Interactive implementations of thermodynamics-based RNA structure and RNA-RNA interaction prediction approaches for example-driven teaching}},
volume = {14},
year = {2018}
}
@article{Suneja2015,
abstract = {Music is present everywhere around us. It is present in car rides, hotels, homes, television shows, movies, etc. With a huge demand of songs for bands, movies, etc., writers and singers are pressurised to produce new songs, but face the challenge of ensuring that they are not copying an already existing song in any way. With the growing music industry, cases of plagiarism have become a critical concern for musicians. An enormous number of musical tracks are released every year. So, there arises a need of a reliable and easy way to search through the huge database of songs that match the query song. In this paper, we have implemented the five similarity measure algorithms in MATLAB and did the comparative analysis of using them to distinguish among three sets of songs: a pair of plagiarized songs, a pair of same song with different lengths, and a random pair of songs to find the best fit algorithm for plagiarism detection.},
annote = {Apesar de ser um artigo breve e superficial, ele {\'{e}} muito importante pois mostra uma an{\'{a}}lise comparativa de processamento de 5 algoritmos Utilizados em Music Similarity:
Chaves: 
Measure Evaluation},
author = {Suneja, Kriti and Bansal, Malti},
doi = {10.1109/INDICON.2015.7443304},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Suneja, Bansal - 2015 - Comparison of time series similarity measures for plagiarism detection in music.pdf:pdf},
isbn = {978-1-4673-7399-9},
issn = {2325-940X},
journal = {2015 Annual IEEE India Conference (INDICON)},
number = {2},
pages = {1--6},
title = {{Comparison of time series similarity measures for plagiarism detection in music}},
url = {http://ieeexplore.ieee.org/document/7443304/},
year = {2015}
}
@article{Foster2014,
abstract = {We propose string compressibility as a descriptor of temporal structure in audio, for the purpose of determining musical similarity. Our descriptors are based on computing track-wise compression rates of quantised audio features, using multiple temporal resolutions and quantisation granularities. To verify that our descriptors capture musically relevant information, we incorporate our descriptors into similarity rating prediction and song year prediction tasks. We base our evaluation on a dataset of 15500 track excerpts of Western popular music, for which we obtain 7800 web-sourced pairwise similarity ratings. To assess the agreement among similarity ratings, we perform an evaluation under controlled conditions, obtaining a rank correlation of 0.33 between intersected sets of ratings. Combined with bag-of-features descriptors, we obtain performance gains of 31.1{\%} and 10.9{\%} for similarity rating prediction and song year prediction. For both tasks, analysis of selected descriptors reveals that representing features at multiple time scales benefits prediction accuracy.},
annote = {Exemplo de Implementa{\c{c}}{\~{a}}o Hybrid ou Algoritmos Adaptados.
Interessante pois mistura diversas abordagens e apresenta algumas tecnicas de avalia{\c{c}}{\~{a}}o como Spearman´s e Kendall´s
Chaves: 
Music Similarity
Hybrid
Measure Evaluation},
archivePrefix = {arXiv},
arxivId = {1402.6926},
author = {Foster, Peter and Mauch, Matthias and Dixon, Simon},
doi = {10.1109/TASLP.2014.2357676},
eprint = {1402.6926},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Foster, Mauch, Dixon - 2014 - Sequential complexity as a descriptor for musical similarity.pdf:pdf},
issn = {23299290},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
keywords = {Music content analysis,Musical similarity measures,Time series complexity},
number = {12},
pages = {1965--1977},
title = {{Sequential complexity as a descriptor for musical similarity}},
volume = {22},
year = {2014}
}
@article{Ren2012,
abstract = {A music piece can be considered as a sequence of sound events which represent both short-term and long-term temporal information. However, in the task of automatic music genre classification, most of text-categorization-based approaches could only capture temporal local dependencies (e.g., unigram and bigram-based occurrence statistics) to represent music contents. In this paper, we propose the use of time-constrained sequential patterns (TSPs) as effective features for music genre classification. First of all, an automatic language identification technique is performed to tokenize each music piece into a sequence of hidden Markov model indices. Then TSP mining is applied to discover genre-specific TSPs, followed by the computation of occurrence frequencies of TSPs in each music piece. Finally, support vector machine classifiers are employed based on these occurrence frequencies to perform the classification task. Experiments conducted on two widely used datasets for music genre classification, GTZAN and ISMIR2004Genre, show that the proposed method can discover more discriminative temporal structures and achieve a better recognition accuracy than the unigram and bigram-based statistical approach.},
annote = {Chaves: 
statistical},
author = {Ren, Jia Min and Jang, Jyh Shing Roger},
doi = {10.1109/TASL.2011.2172426},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren, Jang - 2012 - Discovering time-constrained sequential patterns for music genre classification.pdf:pdf},
isbn = {1558-7916},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Data mining,Hidden Markov model (HMM),Music genre classification,Time-constrained sequential pattern (TSP)},
number = {4},
pages = {1134--1144},
title = {{Discovering time-constrained sequential patterns for music genre classification}},
volume = {20},
year = {2012}
}
@article{Raden-2018-websrv,
abstract = {The Freiburg RNA tools webserver is a well established online resource for RNA-focused research. It provides a unified user interface and comprehensive result visualization for efficient command line tools. The webserver includes RNA-RNA interaction prediction (IntaRNA, CopraRNA, metaMIR), sRNA homology search (GLASSgo), sequence-structure alignments (LocARNA, MARNA, CARNA, ExpaRNA), CRISPR repeat classification (CRISPRmap), sequence design (antaRNA, INFO-RNA, SECISDesign), structure aberration evaluation of point mutations (RaSE), and RNA/protein-family models visualization (CMV), and other methods. Open education resources offer interactive visualizations of RNA structure and RNA-RNA interaction prediction as well as basic and advanced sequence alignment algorithms. The services are freely available at http://rna.informatik.uni-freiburg.de.},
author = {Raden, Martin and Ali, Syed M and Alkhnbashi, Omer S and Busch, Anke and Costa, Fabrizio and Davis, Jason A and Eggenhofer, Florian and Gelhausen, Rick and Georg, Jens and Heyne, Steffen and Hiller, Michael and Kundu, Kousik and Kleinkauf, Robert and Lott, Steffen C and Mohamed, Mostafa M and Mattheis, Alexander and Miladi, Milad and Richter, Andreas S and Will, Sebastian and Wolff, Joachim and Wright, Patrick R and Backofen, Rolf},
doi = {10.1093/nar/gky329},
file = {:C$\backslash$:/Wolff/Referencias QBP/Raden-2018-websrv.pdf:pdf},
issn = {1362-4962},
journal = {Nucleic Acids Research},
number = {W1},
pages = {W25--W29},
title = {{Freiburg RNA tools: a central online resource for RNA-focused research and teaching}},
volume = {46},
year = {2018}
}
@article{Jayapriya2015,
abstract = {{\textcopyright} 2015 IEEE. Sequence analysis paves way for structural and functional analysis in Bioinformatics. The preliminary step for this sequence analysis is aligning the molecular sequences. This paper introduces parallelism in aligning multiple sequences by parallelizing a bio-inspired algorithm called Grey Wolf Optimizer (GWO) technique. Owing to the tradeoff between accurate solutions and less computational time, many heuristic algorithms are developed. The GWO algorithm involves search agents, which are treated as initial solutions for the optimization problem. Data parallelism is employed in the initialization phase and generation phase. This technique is implemented in Quadro 4000 a CUDA based GPU using threads. The results show that the proposed algorithm reduces the computational time than other existing ones.},
annote = {Resolvi manter o artigo pois fiquei impressionado com as possibilidades de usar o mesmo para alinhamento de faixas polifonicas da mesma forma que foi utilizado o para alinhar as monof{\^{o}}nicas.
Olha o sobrenome do inventor do algoritmo: Gery Wolf... Uau!
Chaves:
Music Similarity
Smith Waterman SW
GWO Grey Wolf Optimizer},
author = {Jayapriya, J. and Arock, Michael},
doi = {10.1109/ICACCI.2015.7275611},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jayapriya, Arock - 2015 - A parallel GWO technique for aligning multiple molecular sequences.pdf:pdf},
isbn = {9781479987917},
journal = {2015 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2015},
pages = {210--215},
title = {{A parallel GWO technique for aligning multiple molecular sequences}},
year = {2015}
}
@inproceedings{Martiniano2017,
abstract = {With the steady growth of the Internet many search websites have emerged, however most of these websites only allow you to perform the search using a textual interface. A more intuitive method for the user would be to use melody snippets of a song to perform this search. In this paper, we present a two-stage query-by-playing (QBP) system using symbolic representations where from a melody snippet of a song it is performed the retrieval of a set of similar songs. On the first stage we perform the alignments and calculate its result rank, which may have draws. Stage two was created to help solving this problem, where a classifier-based filter is applied on the results, reducing the number of draws. A new methodology for evaluating QBP is presented, aiming to understand the impact of the number of notes in the query and some alternatives to verify the robustness of the methods considering wrong and missing notes. In addition, a new method based on machine learning (ML) is presented to filter the results. In the experiments this method always improves the performance of queries regardless of the noise.},
author = {Martiniano, Lucas and {N. Silla}, Carlos},
booktitle = {2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)},
doi = {10.1109/ICTAI.2017.00087},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martiniano, N. Silla - 2017 - BIRITS A Music Information Retrieval System Using Query-by-Playing Techniques.pdf:pdf},
isbn = {978-1-5386-3876-7},
month = {nov},
pages = {535--542},
publisher = {IEEE},
title = {{BIRITS: A Music Information Retrieval System Using Query-by-Playing Techniques}},
url = {https://ieeexplore.ieee.org/document/8371990/},
year = {2017}
}
@article{Smith1981,
abstract = {The identification of maximally homologous subsequences among sets of long sequences is an important problem in tnolecular sequence analysis. The problem is straightforward only if one restricts consideration to cont.igucws subsequences (segments) containing no internal deletions or insertions. The more general problem has its solution in an extension of sequence metrics (Sellers 19i.i: IVaterman el al.. 1976) developed to measure the mininlunl number of "et-cntsr' required to convert one sequence into another. These developments in t.he modern sequence analysis began with the heuristic homology algorithm of Seedleman {\&} Wunsch (1970) which first introduced an iterative matrix method of calculation. Sumerous other heuristic algorithms have been suggested including those of Fitch (1966) and Dayhoff (1969). More mathernat- icallg rigorous algorithms were suggested by Sankoff (1972), Reichert. ef d. (1973) and Beyer el d. (1979), but these were generally not biologically satisfjing or interpretable. Successcame with Sellers (19i4) development of a true metric measure of the distance betweef: sequences. This metric was later generalized by Waterman et al. (1976) to include deletions/insertions of arbitrary length. This metric represents the minimum number of "mutat.iona1 events'' required t,o convert one sequence into another. It is of interest to n0t.e that Smith et al. (1980) hare recently shown that under some conditions the original homology algorithm of Seedleman S. Wunsch (19iO). In this letter we extend the above ideas to find a pair of segments. one from each of two long sequences. such that there is no other pair of segments with greater similarity (homology). The similarity measure used here allows for arbitrary length deletions and insertions. =Ilgorithm},
annote = {Artigo originbal do algoritmos de alinhamento local
Chaves:
string-matching},
author = {Smith, T.F. and Waterman, M.S.},
doi = {10.1016/0022-2836(81)90087-5},
file = {:C$\backslash$:/Users/william.wolff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith, Waterman - 1981 - Identification of common molecular subsequences.pdf:pdf},
isbn = {0022-2836},
issn = {0022-2836},
journal = {Molecular Biology},
pages = {195--197},
pmid = {7265238},
title = {{Identification of common molecular subsequences}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7265238},
volume = {147},
year = {1981}
}
